---
title: "003-Identification_of_Population_Structure_Associated_with_Habitat"
author: "Rebecca Cheek"
date: "2/28/2021"
output: html_document
---


```{r include=FALSE}

#clear memory 

gc()

#Load Libraries

library(tidyverse)
library(pcadapt)
library(qvalue)
library(tidyverse)
library(pegas)
library(ade4)
library(LEA)
library(adegenet)
library(spdep)
library(hierfstat)
library(PopGenReport)
library(ggthemes)
library(mmod)
library(spdep)
library(MASS)
library("poppr")
library("pegas")
library("ape")
library(geodist)
library(vcfR)
library(vegan)
library(reshape2)
library(ggpubr)
library(lme4)
library(MuMIn)
library(gdata)
library(raster)
library(sp)
library(sf)
library(tigris)
library(ggthemes)
library(ggspatial)
library(psych)
library(viridis)
library("ggnewscale")
library(cowplot)
library(maptools)
library(rgdal)
library(gridExtra)
library(RColorBrewer)
library(raster)
library(rgdal)
library(RColorBrewer)


set.seed(666)


```


**PCAdapt** 
	**Description**: PCAdapt uses Principal Components Analysis (PCA) to identify loci showing strong signatures of selection relative to neutral background genomic variation. Here, we will identify putatively adaptive outlier loci using a false discovery rate of 10% and filter these outliers out for downstream landscape genomic analyses to avoid confounding neutral demographic patterns with patterns generated by loci under selection.


```{r message=FALSE, warning=FALSE}

file<-"C:/Users/Rebecca/Colostate/GhalamborLab - Documents/Group Projects/mysis/data/redo_sans_jumbo/pre_filter/filtered_data/imputed_data/mysis_clean_imputed.ped"


mysis.pcadapt <- read.pcadapt(file,type="ped")


#Choose the appropriate K value from scree plot, run PCAdapt, and get summary.
#it looks like K=1 is the most supported (see results) so we will use that criterion for detecting loci under selection


 y <- pcadapt(mysis.pcadapt, K=5) 
 plot(y,option="screeplot") 
 
#The ‘scree plot’ displays in decreasing order the percentage of variance explained by each PC. Up to a constant, it corresponds to the eigenvalues in decreasing order. The ideal pattern in a scree plot is a steep curve followed by a bend and a straight line. The eigenvalues that correspond to random variation lie on a straight line whereas the ones that correspond to population structure lie on a steep curve. We recommend to keep PCs that correspond to eigenvalues to the left of the straight line (Cattell’s rule).
 
 #in this case, It's hard to tell if K=2 or K=n-1 (so 1) should be used. Based on the snmf results, it seems like K=1 is the best choice. Especially because there is very little variance being explained. 

x <- pcadapt(mysis.pcadapt,K=1)

summary(x)


#A Manhattan plot displays log10 of the p-values.

plot(x,option="manhattan")

#Check the distribution of the p-values using a Q plot, showing the top 5% lowest p-values.

plot(x,option="qqplot",threshold=0.05)

#Use q histogram of p-values to confirm that most of the p-values follow the uniform distribution,
#and that there is an excess of small p-values indicating the presence of outliers.

hist(x$pvalues,xlab="p-values",main=NULL,breaks=50)

#For a given ± (number between 0 and 1), SNPs with q-values less than alpha will be considered outliers with an expected false discovery rate bounded by Î±. 
#The false discovery rate is defined as the percentage of false discoveries expected among the list of outlier candidate SNPs.


qval <- qvalue(x$pvalues)$qvalues

#provide a list of candidate SNPs with an expected false discovery rate less than 10%.
alpha <- 0.10 #7 outliers
outliers <- which(qval<alpha)
outliers <- as_tibble(outliers, quote=F)

#Looks like we have 7 potential outliers using our full dataset of 18,441 SNPs

#note that PCAdapt outputs the "order" of the loci rather than the IDs of the loci themselves
# So we will use this output of PCAdapt to filter the loci out of the vcf so we know which SNP the are 

#read back in the "clean" raw file of the snps that passed QC in Plink. The collumns are the snp name with LocusID_Col which can be used to generate a whitelist of snps for neutral populations in Stacks

gen <- read.PLINK("C:/Users/Rebecca/Colostate/GhalamborLab - Documents/Group Projects/mysis/data/redo_sans_jumbo/pre_filter/filtered_data/imputed_data/mysis_clean_imputed.raw", parallel = F)

gen <- as_tibble(gen)

dim(gen)

#create a sequence from 1 to limit of the vcf so the collumns has numbers that can be filtered out using the list from pcadapt
col_id <- as_tibble(seq(1,36882,1))

col_id$snp =  colnames(gen)

#now we can join to see which are the outlier snps
pcaadapt.outliers <- left_join(outliers,col_id, by="value")

##select just the snp name 

pcaadapt.outliers <- pcaadapt.outliers %>% 
  dplyr::select(snp) 

#read in the snp pos information from the original vcf 

#Get the snp position using bcftools 

snp_pos <- read.table("C:/Users/Rebecca/Colostate/GhalamborLab - Documents/Group Projects/mysis/data/redo_sans_jumbo/pre_filter/filtered_data/imputed_data/mysis_clean_imputed_snps.txt")

colnames(snp_pos) <-c("CHROM", "POS", "snp")

dim(snp_pos)


#select the col and pos information from the snp id and make a blacklist 

#the SNP IDs are from the Raw file which includes the genotype. 
pcaadapt_snps<-separate(pcaadapt.outliers, col = snp, into = c("left", "right","genotype"), sep = "_") 


pcaadapt_snps$snp <- paste0(pcaadapt_snps$left, "_", pcaadapt_snps$right)

pcaadapt_snps <- pcaadapt_snps %>% 
  dplyr::select("snp")

blacklist <- left_join(pcaadapt_snps, snp_pos, by="snp")

blacklist <- blacklist %>% 
  dplyr::select("CHROM", "POS")


#write blacklist to remove these FST outliers form the "neutral" data 

 # pgirmess::write.delim(blacklist, file = "C:/Users/Rebecca/Colostate/GhalamborLab - Documents/Group Projects/mysis/data/redo_sans_jumbo/pre_filter/filtered_data/imputed_data/adaptive_snps/mysis_pcadapt_blacklist.txt", quote = FALSE, row.names = FALSE, sep = "\t",col.names = FALSE )


```


RDA_habitat
		Description: Redundancy analysis implemented with the LEA R package to test multiple loci simultaneously for genetic associations with habitat (Elevation and max lake depth) using constrained orthogonal axes. Because the mysis shrimp were sampled from lakes with the same environmental information, then we will need to do a group based approach where we will use allele frequencies for our RDA instead of the individual genotypes.For the population level RDA, we can  read in our allele frequency data and test to see how different the results are from the individual based RDA. 
		We chose RDA because there is very little population structure according to Admixture and our PCA. 
```{r}

#read in the raw plink file and convert to genepop using adegenet
gen <- read.PLINK("C:/Users/Rebecca/Colostate/GhalamborLab - Documents/Group Projects/mysis/data/redo_sans_jumbo/pre_filter/filtered_data/imputed_data/mysis_clean_imputed.raw", parallel = F)

#RDA require complete data frames (i.e., no missing genetic data). 
#convert to a data frame
gen.imp <- as.data.frame(gen)

#Import the environmental data with the locality information, but filter out the individuals that were removed during filtering  

env <- read.csv("C:/Users/Rebecca/Colostate/GhalamborLab - Documents/Group Projects/mysis/data/mysis_env_final.csv")

#order the pred file so that it matches with the genetic data 

env <- env[order(match(env$individual_id, rownames(gen.imp))),]

# Confirm that genotypes and environmental data are in the same order

identical(row.names(gen.imp), env$individual_id)

#convert to a genind object 
gen.imp <- as.genind(gen.imp)

#can now convert genind to genepop using the population IDs (lake name) from the environmental data to get population level allele frequencies for population-based RDA
gen <- genind2genpop(gen.imp, pop=as.factor(env$Lake_name))
 
#convert to a data frame
genfile<- as.data.frame(gen)

genfile <- as.matrix(genfile, row.names =FALSE, col.names=FALSE)

mode(genfile) <- "numeric" #need be be numeric for the rda

#select the environmental variables that we have the strongest a priori hypotheses for regarding selection in the shrimp
#according to our local experts, elevation and max lake depth are the predictors that are the most stable throughout the year, so we will use those 
#filter the Clear Water Individuals out of environmental data since it's all NAs and can't run in the RDA

env$Lake_name <- as.factor(env$Lake_name)

#Select just the lake names and the filter to just the unique lakes 

#select just the unique Lake names 

pred <- env[!duplicated(env$Lake_name),] 

pred <- pred %>%
  dplyr::select(c("elevation.meters_above_sea_level", "max_depth_meters"))


pairs.panels(pred, scale=T)  #they are .16 correlated so we are under .7 cutoff even with the population level data

#make sure all environmental variables are numeric
pred$elevation.meters_above_sea_level <- as.numeric(pred$elevation.meters_above_sea_level)
pred$max_depth_meters <- as.numeric(pred$max_depth_meters)

#Run the RDA  
mysis.rda<- vegan::rda(genfile ~ elevation.meters_above_sea_level+
                        max_depth_meters , data=pred, scale=T)

summary(mysis.rda)

# 
# Biplot scores for constraining variables
# 
#                                     RDA1    RDA2 PC1 PC2 PC3 PC4
# elevation.meters_above_sea_level -0.3882 -0.9216   0   0   0   0
# max_depth_meters                  0.8455 -0.5340   0   0   0   0
# 


#check to see how much of the variation is explained by the model in the R2, and how well the eigenvalues account for the explained variance
vegan::RsquareAdj(mysis.rda) #r2=0.3194104, adjusted r2=0.04717456

summary(eigenvals(mysis.rda, model = "constrained"))
# 
# Importance of components:
#                            RDA1      RDA2
# Eigenvalue            6944.3822 4779.2570
# Proportion Explained     0.5923    0.4077
# Cumulative Proportion    0.5923    1.0000

#We can visualize this information using a screeplot of the canonical eigenvalues by calling `screeplot`:
par(mar=c(.5,.5,.5,.5)) #set margins 

screeplot(mysis.rda) #RDA 1 explains a bit more of the variance


 # signif.full <- anova.cca(mysis.rda, parallel=getOption("mc.cores"), model="full", permutations=99999) 
 # signif.full 

# Permutation test for rda under full model
# Permutation: free
# Number of permutations: 40319
# 
# Model: rda(formula = genfile ~ elevation.meters_above_sea_level + max_depth_meters, data = pred, scale = T)
#          Df Variance      F Pr(>F)
# Model     2    11724 1.1733 0.3119
# Residual  5    24980 
#checking Variance Inflation Factors for the predictor variables used in the model:

vegan::vif.cca(mysis.rda) 

#All values are less than 2, so collinarity shouldn't be a problem. 

#quick plot of the RDA output using the default plotting in `vegan`

plot(mysis.rda, scaling=3)          # default is axes 1 and 2

###### To highlight individuals by lake

#custom color pallett

myCol2 <- c("#ff7f00","#1f78b4","#ffff33","#a6cee3","#33a02c", "#C273F9", "#F973CA", "#17A589" ) # 8 colors for our Lakes 


#Extract the scores from the rda
#Be sure to scale everyting symmetrically by using the scaling=3 argument which will scale based on the sqare root of the eigenvalues
mysis_sam_sco <- scores(mysis.rda, display = "sites", scaling=3)
mysis_env_sco <- scores(mysis.rda, display = "bp", scaling=3)
mysis_sam_tbl <- as_tibble(mysis_sam_sco)
mysis_env_tbl <- as_tibble(mysis_env_sco)
mysis_sam_tbl <- mutate(mysis_sam_tbl, mysis_sam_sco,
                       ccatype = "sites")
mysis_sam_tbl <- cbind(pred, mysis_sam_tbl)
mysis_env_tbl <- mutate(mysis_env_tbl, vgntxt=rownames(mysis_env_sco),
                       ccatype = "bp")


#extract the loading scores of the snps 

mysis_spp_sco <- scores(mysis.rda, display = "species", scaling=3)
mysis_spp_tbl <- as_tibble(mysis_spp_sco)
mysis_spp_tbl <- mutate(mysis_spp_tbl, vgntxt=rownames(mysis_spp_sco),
                       ccatype = "species")


Lakes <- as_tibble(unique(env$Lake_name))

Lakes <- Lakes %>% 
  mutate(value = recode_factor(value,"Lower_Twin"="Lower Twin", "Clear_Water"="Clearwater"))

mysis_sam_tbl$Lake_name <- factor(Lakes$value, 
  levels=c(c("Carter","Clearwater", "Dillon","Grand", "Gross", "Jefferson", "Lower Twin", "Ruedi")))


#Plot the individuals on axis 1 &2 

plot(mysis.rda, type="n", choices=c(1,2))
points(mysis.rda, display="species", pch=20, cex=0.7, col="gray32")          # the SNPs
points(mysis.rda, display="sites", pch=21, cex=1.3, col="gray32", bg=myCol2[mysis_sam_tbl$Lake_name]) # the shrimp
text(mysis.rda, display="bp", col="#0868ac", cex=1)   # the predictors
legend("bottomright", legend=levels(mysis_sam_tbl$Lake_name), bty="n", col="gray32", pch=21, cex=1, pt.bg = myCol2)



#with ggplot 
rda_plot_12 <- ggplot() +
     #geom_point(data=mysis_spp_tbl, aes(x=RDA1,y=RDA2), col="gray32")  +        # the SNPs
  geom_point(data=mysis_sam_tbl,aes(x=RDA1,y=RDA2, fill=Lake_name), shape=21,color="black", size=6) +# the shrimp
 scale_fill_manual(name="Lake Name", values=myCol2, guide= "none")+
  geom_hline(yintercept = 0, lty = 2) +
      geom_vline(xintercept = 0, lty = 2) +
    theme_few()+
     geom_segment(data = mysis_env_tbl, aes(x = 0, y = 0, xend = (RDA1*2),
     yend = (RDA2*2)), arrow = arrow(length = unit(1/2, "picas")),
      color = "black", size=1.2) + #plot the predictors 
  annotate("text", x = (mysis_env_tbl$RDA1*6), y = (mysis_env_tbl$RDA2*4),
             label =c("Elevation", "Max Depth"), color="black", size=5)+
     xlab("RDA1") + ylab("RDA2\n") +
  theme(
      legend.position =c(.17,.95),
          legend.justification = c("right", "top"),
      legend.title = element_text(size=12, face="bold"),
        legend.text = element_text(size=12, face="bold"),
        axis.title=element_text(colour="black", size = 15,face="bold"),
     axis.text=element_text(colour="black", size = 13,face="bold"))


rda_plot_12

```

We can now see if there are any outlier loci that could be associated with our environmental variables, and then use a PCA to see individual variation at those loci. 


```{r}
##########################################
# Identify candidate SNPs
#
##########################################
#Use the loadings of the SNPs (their location) in the ordination
#space to determine which SNPs are candidates for local adaptation.
#The SNP loadings are stored as `species` in the RDA object. We'll extract the SNP loadings from the 2 constrained axes (since we only have 2 predictors):

load.cca <- scores(mysis.rda, choices=c(1:2), display="species")

#If we look at histograms of the loadings on each RDA axis,
#we can see their (relatively normal) distribution. SNPs loading at the center of the distribution are not showing
#a relationship with the environmental predictors; those loading in the tails are, and are more #likely to be under selection as a function of those predictors (or some other predictor correlated with them).


hist(load.cca[,1], main="Loadings on RDA1")
hist(load.cca[,2], main="Loadings on RDA2")



#define the function here as `outliers`, where `x` is the vector of loadings and `z` is the number of standard deviations to use:

#find loadings +/-z sd from mean loading
#locus names of the tails

outliers <- function(x,z){
  lims <- mean(x) + c(-1, 1) * z * sd(x)       
  x[x < lims[1] | x > lims[2]]           
}


#using an sd of 2.5 for moderate selection 

cand1 <- outliers(load.cca[,1],2.5) # 263
cand2 <- outliers(load.cca[,2],2.5) # 110



ncand <- length(cand1)+length(cand2) 
ncand


# 373 if using a moderate selection cutoff of 2.5 sd from the mean

#make a single data frame with the axis, SNP name, & loading:

cand1 <- cbind.data.frame(rep(1,times=length(cand1)), names(cand1), unname(cand1))
cand2 <- cbind.data.frame(rep(2,times=length(cand2)), names(cand2), unname(cand2))


colnames(cand1) <- colnames(cand2) <- c("axis","snp","loading")


cand <- rbind(cand1, cand2)

cand$snp <- as.character(cand$snp)

foo <- matrix(nrow=(ncand), ncol=2)  # 2 columns for 2 predictors

colnames(foo) <- c( "elevation.meters_above_sea_level", "max_depth_meters")

pred <- pred %>% 
  dplyr::select(c( "elevation.meters_above_sea_level",  "max_depth_meters"))


for (i in 1:length(cand$snp)) {
  nam <- cand[i,2]
  snp.gen <- genfile[,nam]
  foo[i,] <- apply(pred,2,function(x) cor(x,snp.gen))
}

cand <- cbind.data.frame(cand,foo)  
head(cand)

dim(cand) #373

#Some of these may be duplicate detections; let's check:


# duplicate detections:
length(cand$snp[duplicated(cand$snp)])
foo <- cbind(cand$axis,duplicated(cand$snp))
table(foo[foo[,1]==1,2])
table(foo[foo[,1]==2,2])


cand <- cand[!duplicated(cand$snp),] #remove duplicates

dim(cand) # final tally is 373


#which predictor each snp is more correlated with

for (i in 1:length(cand$snp)) {
  bar <- cand[i,]
  cand[i,6] <- names(which.max(abs(bar[3:5]))) # gives the variable
  cand[i,7] <- max(abs(bar[3:5]))              # gives the correlation
}

colnames(cand)[6] <- "predictor"
colnames(cand)[7] <- "correlation"

table(cand$predictor)

#for 2.5 sd cutoff
# elevation.meters_above_sea_level                 max_depth_meters 
#                              166                              207 


##To highlight SNPs of just our predictors


sel <- cand$snp
eco <-cand$predictor

eco[eco =="elevation.meters_above_sea_level"] <- '#f2853d'
eco[eco =="max_depth_meters"] <- '#3498DB'

# color by predictor:
col.pred <- rownames(mysis.rda$CCA$v) # pull out all the SNP names


for (i in 1:length(sel)) {           # color code candidate SNPs
  foo <- match(sel[i],col.pred)
  col.pred[foo] <- eco[i]
}

colors <- c("#f2853d","#3498DB")

col.pred[!grepl(paste(colors,collapse="|"), col.pred)] <- '#f1eef6' # non-candidate SNPs assigned transparent color
empty <- col.pred

empty[grep("#f1eef6",empty)] <- rgb(0,1,0, alpha=0) # transparent
empty.outline <- ifelse(empty=="#00FF0000","#00FF0000","gray32")

#Color the depth and elevation snps
bg <- c(c("#f2853d","#3498DB"))


# axes 1 & 2 basic plot

plot(mysis.rda, type="n", scaling=3, xlim=c(-1,1), ylim=c(-1,1))
points(mysis.rda, display="species", pch=21, cex=1, col="grey32", bg=col.pred, scaling=3)
points(mysis.rda, display="species", pch=21, cex=1,col=empty.outline, bg=empty, scaling=3)
text(mysis.rda, scaling=3, display="bp", col="#0868ac", cex=1)
legend("topright",legend=c("Elevation", "Max Depth"), bty="n", col="gray32", pch=21, cex=1, pt.bg=bg)

#extract the loading scores of the snps
mysis_spp_sco <- scores(mysis.rda, display = "species", scaling=3)
mysis_spp_tbl <- as_tibble(mysis_spp_sco)
mysis_spp_tbl_median<- mutate(mysis_spp_tbl, vgntxt=rownames(mysis_spp_sco),
                       ccatype = "species")

mysis_spp_tbl$colors <- col.pred

#select just the neutral snps and plot those first in ggplot
mysis_spp_neutral <- mysis_spp_tbl %>% 
  filter(colors=="#f1eef6")

#select out the neutral snps to get the adaptive snps 
mysis_spp_tbl <- mysis_spp_tbl %>% 
  filter(!colors=="#f1eef6")


rda_plot_snps <- ggplot()+
   geom_point(data=mysis_spp_neutral, aes(x=RDA1,y=RDA2), col="grey40", alpha=.3, size =2)  +  # the neutral SNPs
       geom_point(data=mysis_spp_tbl, aes(x=RDA1,y=RDA2, color=colors), size=3) + 
       scale_color_manual(values=c("#f2853d","#3498DB"),  name="", labels = c("Elevation", "Max Lake Depth"))+
  #transparent outlines so you can see all the outlier snps over the neutral ones
  geom_hline(yintercept = 0, lty = 2) +
      geom_vline(xintercept = 0, lty = 2) +
  expand_limits(x = c(-.1, .12), y = c(-0.05, 0.05))+
    theme_few()+
     geom_segment(data = mysis_env_tbl, aes(x = 0, y = 0, xend = (RDA1*.35),
     yend = (RDA2*.35)), arrow = arrow(length = unit(1/2, "picas")),
     color = "black", size=1) + #plot the predictors 
 # annotate("text", x = (mysis_env_tbl$RDA1*.3), y = (mysis_env_tbl$RDA2*.5),
 #              label =c("Elevation", "Max Lake Depth") , color="black", size=5)+
   xlab("RDA1") + ylab("RDA2") +
  theme(legend.position =c(.95,.97),
        legend.justification = c("right", "top"),
    legend.title = element_text(size=10, face="bold"),
        legend.text = element_text(size=10, face="bold"),
        axis.title=element_text(colour="black", size = 15,face="bold"),
     axis.text=element_text(colour="black", size = 13,face="bold"))

rda_plot_snps


```
Make a whitelist of outliers and see which outliers are correlated with which predictor
```{r}

#make a list of SNPs 

#how many SNPs with each predictor
RDA_snps <- cand

RDA_snps <- separate(RDA_snps, snp ,
                     c("Locus ID", "Col", "gen"))

RDA_snps<- RDA_snps [!duplicated(RDA_snps[c("Locus ID", "Col","predictor")]),]


dim(RDA_snps) #  215 total candidate loci from the RDA

table(RDA_snps$predictor)

# elevation.meters_above_sea_level                 max_depth_meters 
#                               95                              120


#the SNP IDs are from the raw file which includes the genotype. 
whitelist <- separate(cand, col = snp, into = c("left", "right","genotype"), sep = "_") 


whitelist$snp_id <- paste0(whitelist$left, "_", whitelist$right)

#get the col pos and snp id from the original vcf

pos_snp <- read.table("C:/Users/Rebecca/Colostate/GhalamborLab - Documents/Group Projects/mysis/data/redo_sans_jumbo/pre_filter/filtered_data/imputed_data/mysis_clean_imputed_snps.txt")

colnames(pos_snp) <- c("chrom","pos","snp_id")

whitelist <- left_join(whitelist, pos_snp, by="snp_id")

sum(is.na(whitelist$chrom)) #no Nas so RDA whitelist is ready to use

#Select just the chrom and pos information from the RDA outliers to filter out using vcftools
whitelist <- whitelist %>% 
  dplyr::select(c("chrom", "pos"))

dim(distinct(whitelist)) #215
    
# #write out whitelist to get our adaptive loci
# pgirmess::write.delim(whitelist, file = "C:/Users/Rebecca/Colostate/GhalamborLab - Documents/Group Projects/mysis/data/redo_sans_jumbo/pre_filter/filtered_data/imputed_data/adaptive_snps/mysis_RDA_adaptive_snps.txt", quote = FALSE, row.names = FALSE, sep = "\t",col.names = FALSE )


```

Check to see how many of the loci are shared between the RDA and PCAdapt 


```{r}

#make a large list of SNPs
pcaadapt.outliers <- read.table("C:/Users/Rebecca/Colostate/GhalamborLab - Documents/Group Projects/mysis/data/redo_sans_jumbo/pre_filter/filtered_data/imputed_data/adaptive_snps/mysis_pcadapt_blacklist.txt")

RDA_snps <- read.table("C:/Users/Rebecca/Colostate/GhalamborLab - Documents/Group Projects/mysis/data/redo_sans_jumbo/pre_filter/filtered_data/imputed_data/adaptive_snps/mysis_RDA_adaptive_snps.txt")


all_outliers <- rbind(RDA_snps, pcaadapt.outliers)


colnames(all_outliers) <- c("chrom","pos")

#keep only the unique loci and col
all_outliers <- distinct(all_outliers)

dim(all_outliers) #221 total candidate loci


#between the RDA and PCAdapt, how many l0ci are shared?


overlap_snps <- semi_join(pcaadapt.outliers, RDA_snps, by=c("V1", "V2")) #1 overlap at pos 5813435

#get the col pos and snp id from the original vcf

pos_snp <- read.table("C:/Users/Rebecca/Colostate/GhalamborLab - Documents/Group Projects/mysis/data/redo_sans_jumbo/pre_filter/filtered_data/imputed_data/mysis_clean_imputed_snps.txt")

colnames(pos_snp) <- c("chrom","pos","snp_id")

whitelist <- left_join(all_outliers, pos_snp, by=c("chrom","pos"))

sum(is.na(whitelist$chrom)) #no Nas so RDA whitelist is ready to use

#Select just the chrom and pos information from the RDA outliers to filter out using vcftools
whitelist <- whitelist %>% 
  dplyr::select(c("chrom", "pos"))

dim(distinct(whitelist)) #221
    
# #write out whitelist to get our full adaptive loci dataset 
#will remove these to get our "neutral" popualtion stats and 
# pgirmess::write.delim(whitelist, file = "C:/Users/Rebecca/Colostate/GhalamborLab - Documents/Group Projects/mysis/data/redo_sans_jumbo/pre_filter/filtered_data/imputed_data/adaptive_snps/mysis_adaptive_snps_all.txt", quote = FALSE, row.names = FALSE, sep = "\t",col.names = FALSE )

#to get a whitelist for populations, need to use the snp id to get the col and pos info of the loci not flagged as outliers

whitelist_pop <- anti_join(pos_snp,all_outliers,  by=c("chrom","pos"))

#separate the snp id into col and pos to use as a whitelist in populations for pairwise fst estimates
whitelist_pop <-separate(whitelist_pop, col = snp_id, into = c("COL","POS"), sep = "_") 

whitelist_pop <- whitelist_pop %>% 
  dplyr::select(c("COL","POS"))

 # pgirmess::write.delim(whitelist_pop, file = "C:/Users/Rebecca/Colostate/GhalamborLab - Documents/Group Projects/mysis/data/redo_sans_jumbo/pre_filter/filtered_data/imputed_data/neutral_snps/mysis_neutral_snps_whitelist.txt", quote = FALSE, row.names = FALSE, sep = "\t",col.names = FALSE )

```

Since we used population-based RDA of candidate markers to identify drivers of adaptive divergence, we can use an individual-based PCA to investigate adaptive differentiation.


Filter to just the "adaptive SNPs" from RDA from the full vcf using bcftools and vcftools.  

```{sh}

#get the positional information from the original imputed VF
bcftools query -f '%CHROM\t%POS\t%ID\n' mysis_clean_imputed.vcf > mysis_clean_imputed_snps.txt

#filter to just the RDA SNPs
vcftools --vcf ./mysis_clean_imputed.vcf --positions adaptive_snps/mysis_adaptive_snps_all.txt --recode --recode-INFO-all --out ./adaptive_snps/mysis_adaptive_snps.vcf
 
 #After filtering, kept 221 out of a possible 18441 Sites
 
 #use --exclude-positions to make the neutral dataset 


```


Filter to just the "neutral SNPs" from RDA from the full vcf using bcftools and vcftools.  

```{sh}

#filter to just the RDA SNPs
vcftools --vcf ./mysis_clean_imputed.vcf --exclude-positions adaptive_snps/mysis_adaptive_snps_all.txt --recode --recode-INFO-all --out ./neutral_snps/mysis_neutral_snps.vcf
 
 #After filtering, kept 18220 out of a possible 18441 Sites
 
#get the SNP info using bcftools and make a whitelist for STACKS to get fst


```



PCA of just the RDA outliers. Since we can say more about what these outliers are actually associated with, it will be easier to interpret the PCA results. Furthermore, because we generated this list of adative snps from the RDA it will be more informative as to what the model is acctually seeing.  

```{r}

#plot out the imputed snps following filtering and imputation

mysis_gen <- read.PLINK("C:/Users/Rebecca/Colostate/GhalamborLab - Documents/Group Projects/mysis/data/redo_sans_jumbo/pre_filter/filtered_data/imputed_data/adaptive_snps/mysis_adaptive_snps.raw", parallel = F)

dim(mysis_gen) #221 adaptive SNPs

#read plink reads it in as a genlight but scripts wants a genind so convert to a dataframe and then genind 

gen <-as.matrix(mysis_gen)

#including just in case
# If the the individual_ids have the population data too, need to pull just the individual ID so I can merge the population data into the genind correctly 
# 
# individual_id <- as_tibble(rownames(gen))
# 
# individual_id <- separate(individual_id, value ,
#                      c("pop", "indiv", "num", 'num2'))
# 
# #replace NA with num
# 
# individual_id$num2[is.na(individual_id$num2)] <- as.character(individual_id$num[is.na(individual_id$num2)])
# 
# individual_id <- individual_id %>% 
#   mutate(indiv = recode_factor(indiv,"Twin"="LOWT", "Water"="CLER"))
# 
# 
# individual_id <- individual_id %>% 
#   dplyr::select(c("indiv", "num2"))
# 
# individual_id$indiv_id <- paste0(individual_id$indiv, "_", individual_id$num2)
# 
# rownames(gen) <- individual_id$indiv_id

mode(gen) <- "numeric"

sum(is.na(gen)) 

#now we can use the rda function from the vegan package which is the same thing as a pca

mysis.pca1 <- rda(gen) #PCA using rda functionwithout predictors to run a PCA


summary(mysis.pca1)$cont 


screeplot(mysis.pca1, main = "Screeplot: Eigenvalues of Predictor Variables") #10 PCs 


#We'll store our synthetic PC axis predictor as pred.PC1 for use in mapping.

pred.PC1 <- scores(mysis.pca1, choices=1, display="sites", scaling=0)


#quick and dirty plot
plot(pred.PC1)

#order the pred file so that it matches with the genetic data 

env <- read.csv("C:/Users/Rebecca/Colostate/GhalamborLab - Documents/Group Projects/mysis/data/mysis_env_final.csv")

env <- env[order(match(env$individual_id, rownames(gen))),]


#make sure the order of the phenotype and the genetic data are the same
identical(env$individual_id, rownames(gen))


##plot PCA in ordination space
###### To highlight individuals by library 
#custom color pallet
myCol2 <- c("#ff7f00","#1f78b4","#ffff33","#a6cee3","#33a02c", "#C273F9", "#F973CA", "#17A589" ) # 9 colors for our Lakes plus 2 phenotypes


#Extract the scores from the pca
#Be sure to scale everything symmetrically by using the scaling=3 argument which will scale based on the square root of the eigenvalues
mysis_sam_sco <- scores(mysis.pca1, choices = 1:10, display = "sites")
mysis_sam_tbl <- as_tibble(mysis_sam_sco)
mysis_sam_tbl <- mutate(mysis_sam_tbl, individual_id=rownames(mysis_sam_sco),
                       ccatype = "sites")


mysis_sam_tbl <- left_join(env, mysis_sam_tbl, by="individual_id")



#extract the loading scores of the snps 

mysis_spp_sco <- scores(mysis.pca1, display = "species")
mysis_spp_tbl <- as_tibble(mysis_spp_sco)
mysis_spp_tbl <- mutate(mysis_spp_tbl, vgntxt=rownames(mysis_spp_sco),
                       ccatype = "species")
 

mysis_sam_tbl <- mysis_sam_tbl %>% 
  dplyr::mutate(Lake_name = recode_factor(Lake_name,"Lower_Twin"="Lower Twin", "Clear_Water"="Clearwater"))

mysis_sam_tbl$Lake_name <- factor(mysis_sam_tbl$Lake_name, 
   levels=c("Carter", "Clearwater", "Dillon","Grand", "Gross", "Jefferson", "Lower Twin", "Ruedi"))




#with ggplot
pc_plot_12 <- ggplot() +
  geom_point(data=mysis_sam_tbl,aes(x=PC1,y=PC2, fill=Lake_name), shape=21,  color="black", size=7) +# the shrimp
  scale_fill_manual(values = myCol2, guide="none")+ #guide="none" to remove ledgend
  geom_hline(yintercept = 0, lty = 2) +
  geom_vline(xintercept = 0, lty = 2) +
  theme_few()+
  xlab("PC Axis 1 (4.12%)") + ylab("PC Axis 2 (3.45%)") +
  theme(
     legend.position =c(.18,.98),
         legend.justification = c("right", "top"),
         legend.title = element_text(size=12, face="bold"),
         legend.text = element_text(size=12, face="bold"),
        axis.title=element_text(colour="black", size = 15,face="bold"),
        axis.text=element_text(colour="black", size = 13,face="bold"),
        plot.background = element_rect(fill = "transparent",colour = NA))

pc_plot_12

#with ggplot
pc_plot_13 <- ggplot() +
  geom_point(data=mysis_sam_tbl,aes(x=PC1,y=PC3, fill=Lake_name), shape=21,  color="black", size=4) +# the shrimp
  scale_fill_manual(values = myCol2)+
  geom_hline(yintercept = 0, lty = 2) +
  geom_vline(xintercept = 0, lty = 2) +
  theme_few()+
  xlab("PC Axis 1 4.12%)") + ylab("PC Axis 3 (3.00%)") +
  theme(legend.position =NULL, # ,c(.18,.98) margins
        legend.justification = c("right", "top"),
        legend.title = element_text(size=12, face="bold"),
        legend.text = element_text(size=12, face="bold"),
        axis.title=element_text(colour="black", size = 15,face="bold"),
        axis.text=element_text(colour="black", size = 13,face="bold"),
        plot.background = element_rect(fill = "transparent",colour = NA))

pc_plot_13




#with ggplot
pc_plot_23 <- ggplot() +
  geom_point(data=mysis_sam_tbl,aes(x=PC2,y=PC3, fill=Lake_name), shape=21,  color="black", size=4) +# the shrimp
  scale_fill_manual(values = myCol2)+
  geom_hline(yintercept = 0, lty = 2) +
  geom_vline(xintercept = 0, lty = 2) +
  theme_few()+
  xlab("PC Axis 2 (3.45%)") + ylab("PC Axis 3 (3.00%)") +
  theme(legend.position =NULL, #c(.18,.98)
        legend.justification = c("right", "top"),
        legend.title = element_text(size=12, face="bold"),
        legend.text = element_text(size=12, face="bold"),
        axis.title=element_text(colour="black", size = 15,face="bold"),
        axis.text=element_text(colour="black", size = 13,face="bold"),
        plot.background = element_rect(fill = "transparent",colour = NA))

pc_plot_23

#with ggplot
pc_plot_34 <- ggplot() +
  geom_point(data=mysis_sam_tbl,aes(x=PC3,y=PC4, fill=Lake_name), shape=21,  color="black", size=4) +# the shrimp
  scale_fill_manual(values = myCol2)+
  geom_hline(yintercept = 0, lty = 2) +
  geom_vline(xintercept = 0, lty = 2) +
  theme_few()+
  xlab("PC Axis 3 (3.00%)") + ylab("PC Axis 4 (2.95%)") +
  theme(legend.position =c(.18,.98),
        legend.justification = c("right", "top"),
        legend.title = element_text(size=12, face="bold"),
        legend.text = element_text(size=12, face="bold"),
        axis.title=element_text(colour="black", size = 15,face="bold"),
        axis.text=element_text(colour="black", size = 13,face="bold"),
        plot.background = element_rect(fill = "transparent",colour = NA))

pc_plot_34

#with ggplot
pc_plot_14 <- ggplot() +
  geom_point(data=mysis_sam_tbl,aes(x=PC1,y=PC4, fill=Lake_name), shape=21,  color="black", size=4) +# the shrimp
  scale_fill_manual(values = myCol2)+
  geom_hline(yintercept = 0, lty = 2) +
  geom_vline(xintercept = 0, lty = 2) +
  theme_few()+
  xlab("PC Axis 1 (4.12%)") + ylab("PC Axis 4 (2.94%)") +
  theme(legend.position =c(.18,.98),
        legend.justification = c("right", "top"),
        legend.title = element_text(size=12, face="bold"),
        legend.text = element_text(size=12, face="bold"),
        axis.title=element_text(colour="black", size = 15,face="bold"),
        axis.text=element_text(colour="black", size = 13,face="bold"),
        plot.background = element_rect(fill = "transparent",colour = NA))

pc_plot_14

#with ggplot
pc_plot_45 <- ggplot() +
  geom_point(data=mysis_sam_tbl,aes(x=PC4,y=PC5, fill=Lake_name), shape=21,  color="black", size=4) +# the shrimp
  scale_fill_manual(values = myCol2)+
  geom_hline(yintercept = 0, lty = 2) +
  geom_vline(xintercept = 0, lty = 2) +
  theme_few()+
  xlab("PC Axis 4 (2.95%)") + ylab("PC Axis 5 (2.80%)") +
  theme(legend.position =c(.18,.98),
        legend.justification = c("right", "top"),
        legend.title = element_text(size=12, face="bold"),
        legend.text = element_text(size=12, face="bold"),
        axis.title=element_text(colour="black", size = 15,face="bold"),
        axis.text=element_text(colour="black", size = 13,face="bold"),
        plot.background = element_rect(fill = "transparent",colour = NA))

pc_plot_45

#with ggplot
pc_plot_56 <- ggplot() +
  geom_point(data=mysis_sam_tbl,aes(x=PC5,y=PC6, fill=Lake_name), shape=21,  color="black", size=4) +# the shrimp
  scale_fill_manual(values = myCol2)+
  geom_hline(yintercept = 0, lty = 2) +
  geom_vline(xintercept = 0, lty = 2) +
  theme_few()+
  xlab("PC Axis 5 (2.80%)") + ylab("PC Axis 6 (2.78%)") +
  theme(legend.position =c(.18,.98),
        legend.justification = c("right", "top"),
        legend.title = element_text(size=12, face="bold"),
        legend.text = element_text(size=12, face="bold"),
        axis.title=element_text(colour="black", size = 15,face="bold"),
        axis.text=element_text(colour="black", size = 13,face="bold"),
        plot.background = element_rect(fill = "transparent",colour = NA))

pc_plot_56

#with ggplot
pc_plot_67 <- ggplot() +
  geom_point(data=mysis_sam_tbl,aes(x=PC6,y=PC7, fill=Lake_name), shape=21,  color="black", size=4) +# the shrimp
  scale_fill_manual(values = myCol2)+
  geom_hline(yintercept = 0, lty = 2) +
  geom_vline(xintercept = 0, lty = 2) +
  theme_few()+
  xlab("PC Axis 6 (2.78%)") + ylab("PC Axis 7 (2.59%)") +
  theme(legend.position =c(.18,.98),
        legend.justification = c("right", "top"),
        legend.title = element_text(size=12, face="bold"),
        legend.text = element_text(size=12, face="bold"),
        axis.title=element_text(colour="black", size = 15,face="bold"),
        axis.text=element_text(colour="black", size = 13,face="bold"),
        plot.background = element_rect(fill = "transparent",colour = NA))

pc_plot_67

#with ggplot
pc_plot_78 <- ggplot() +
  geom_point(data=mysis_sam_tbl,aes(x=PC7,y=PC8, fill=Lake_name), shape=21,  color="black", size=4) +# the shrimp
  scale_fill_manual(values = myCol2)+
  geom_hline(yintercept = 0, lty = 2) +
  geom_vline(xintercept = 0, lty = 2) +
  theme_few()+
  xlab("PC Axis 7 (2.59%)") + ylab("PC Axis 8 (2.40%)") +
  theme(legend.position =c(.18,.98),
        legend.justification = c("right", "top"),
        legend.title = element_text(size=12, face="bold"),
        legend.text = element_text(size=12, face="bold"),
        axis.title=element_text(colour="black", size = 15,face="bold"),
        axis.text=element_text(colour="black", size = 13,face="bold"),
        plot.background = element_rect(fill = "transparent",colour = NA))

pc_plot_78

#with ggplot
pc_plot_89 <- ggplot() +
  geom_point(data=mysis_sam_tbl,aes(x=PC8,y=PC9, fill=Lake_name), shape=21,  color="black", size=4) +# the shrimp
  scale_fill_manual(values = myCol2)+
  geom_hline(yintercept = 0, lty = 2) +
  geom_vline(xintercept = 0, lty = 2) +
  theme_few()+
  xlab("PC Axis 8 (2.40%)") + ylab("PC Axis 9 (2.30%)") +
  theme(legend.position =c(.18,.98),
        legend.justification = c("right", "top"),
        legend.title = element_text(size=12, face="bold"),
        legend.text = element_text(size=12, face="bold"),
        axis.title=element_text(colour="black", size = 15,face="bold"),
        axis.text=element_text(colour="black", size = 13,face="bold"),
        plot.background = element_rect(fill = "transparent",colour = NA))

pc_plot_89

#with ggplot
pc_plot_910 <- ggplot() +
  geom_point(data=mysis_sam_tbl,aes(x=PC9,y=PC10, fill=Lake_name), shape=21,  color="black", size=4) +# the shrimp
  scale_fill_manual(values = myCol2)+
  geom_hline(yintercept = 0, lty = 2) +
  geom_vline(xintercept = 0, lty = 2) +
  theme_few()+
  xlab("PC Axis 9 (2.30%)") + ylab("PC Axis 10 (2.21%)") +
  theme(legend.position =c(.18,.98),
        legend.justification = c("right", "top"),
        legend.title = element_text(size=12, face="bold"),
        legend.text = element_text(size=12, face="bold"),
        axis.title=element_text(colour="black", size = 15,face="bold"),
        axis.text=element_text(colour="black", size = 13,face="bold"),
        plot.background = element_rect(fill = "transparent",colour = NA))

pc_plot_910

```
We see no evidence of adaptive differentiation in the top 10 PC axes. PC1 and PC2 shows maybe some limited variation between populations, but not clear clustering.


We can now use the snps from the PCAdapt analysis and RDA to see if there are any genes or regions nearby that are associated with hypoxia, or heat shock proteins. 
Based on our LD estimates in section 1, it looks like there is fairly low LD in the shrimp data. So we will just pull the 350 bp consensus sequences from our SNP targets and BLAST them to see if they align to any known genes.  

Extracting positions from the catalog fasta to use in Blast.

Start with PCAdapt outliers 

```{r}
#option to get positional information from vcf
vcf_pos <- (read.vcfR("C:/Users/Rebecca/Colostate/GhalamborLab - Documents/Group Projects/mysis/data/redo_sans_jumbo/pre_filter/filtered_data/imputed_data/mysis_clean_imputed.vcf")) 

#extract the positional collumns
vcf_pos <- as.data.frame(vcf_pos@fix)

vcf_pos$POS <- as.integer(vcf_pos$POS)

colnames(pcaadapt.outliers) <- c("CHROM","POS")

#merge the RDA cands to the position information

pcadapt.pos.info <- left_join(pcaadapt.outliers, vcf_pos, by= c("CHROM","POS"))

pcadapt.pos.info$POS <- as.numeric(pcadapt.pos.info$POS)

#add 350

pcadapt.pos.info$pos.min <- 0

pcadapt.pos.info$pos.min[pcadapt.pos.info$pos.min<0] <- 0 #convert negative values to zero so it'll just be the start of the file

pcadapt.pos.info$pos.max <- 350

#make a new collumn that sepperates out position info 
pcadapt.pos.info$pos.range <- paste(pcadapt.pos.info$pos.min,pcadapt.pos.info$pos.max, sep="-")


pcadapt.pos.info$sca.snp <- paste(pcadapt.pos.info$CHROM,pcadapt.pos.info$snp, sep=".")

#write a text file with the snp name and position range 
pcadapt.pos.info$fasta.range <- paste(pcadapt.pos.info$POS, pcadapt.pos.info$pos.range, sep=":")


pcadapt.pos.info <- as_tibble(pcadapt.pos.info$fasta.range)

# add a backslash to the end of the collumns 

pcadapt.pos.info <- as_tibble(paste(pcadapt.pos.info$value, " \\"))
 
# write_csv(pcadapt.pos.info, "C:/Users/Rebecca/Colostate/GhalamborLab - Documents/Group Projects/mysis/data/redo_sans_jumbo/pre_filter/filtered_data/imputed_data/adaptive_snps/mysis.pcadapt.BLAST.fasta.coor.csv", col_names=F)


```



```{r}

#option to get positional information from vcf
vcf_pos <- (read.vcfR("C:/Users/Rebecca/Colostate/GhalamborLab - Documents/Group Projects/mysis/data/redo_sans_jumbo/pre_filter/filtered_data/imputed_data/mysis_clean_imputed.vcf")) 

#extract the positional collumns
vcf_pos <- as.data.frame(vcf_pos@fix)


#add the ref and alternate snps

vcf_pos$REF <- paste0(vcf_pos$ID, "_", vcf_pos$REF)
 
vcf_pos$ALT <- paste0(vcf_pos$ID, "_", vcf_pos$ALT)

#also add a HET snp

vcf_pos$HET <- "HET"
 
vcf_pos$HET <- paste0(vcf_pos$ID, "_", vcf_pos$HET)
 
# Convert the wide data to long
vcf_pos <- gather(vcf_pos, condition, snp, c(REF,ALT,HET), factor_key=TRUE)

vcf_pos <- as_tibble(vcf_pos)
#because we don't have chromosomes all we have is the catalog locus ID which is imbedded int he snp info, so need to extract that 

#make a new collumn that sepperates out position info 

vcf_pos<- tidyr::separate(vcf_pos, col=ID , into=
               c("Locus ID", "Col"), sep="_")

#select just the catalog locus ID, snp and position collumns

vcf_pos <- vcf_pos %>% 
  dplyr::select(c("Locus ID","POS", "snp")) %>% 
  dplyr::rename( "CHROM"="Locus ID")



#merge the RDA cands to the position information

rda.pos.info <- left_join(cand, vcf_pos, by= "snp")

rda.pos.info$POS <- as.numeric(rda.pos.info$POS)

#Subtract and add 350 from the position to get range to extract from genomic fasta to be used for blast searching.

rda.pos.info$pos.min <- 0

rda.pos.info$pos.min[rda.pos.info$pos.min<0] <- 0 #convert negative valuse to zero so it'll just be the start of the file

rda.pos.info$pos.max <- 350

#make a new collumn that sepperates out position info 
rda.pos.info$pos.range <- paste(rda.pos.info$pos.min,rda.pos.info$pos.max, sep="-")


rda.pos.info$sca.snp <- paste(rda.pos.info$CHROM,rda.pos.info$snp, sep=".")

#write a text file with the snp name and position range 
rda.pos.info$fasta.range <- paste(rda.pos.info$CHROM, rda.pos.info$pos.range, sep=":")


rda.blast.info <- as_tibble(rda.pos.info$fasta.range)

# add a backslash to the end of the columns 

rda.blast.info <- as_tibble(paste(rda.blast.info$value, " \\"))
 
# #write csv and then copy paste information into RDA_snps_fasta.sh below
 # write_csv(rda.blast.info,"C:/Users/Rebecca/Colostate/GhalamborLab - Documents/Group Projects/mysis/data/redo_sans_jumbo/pre_filter/filtered_data/imputed_data/adaptive_snps/mysis_pop_RDA_BLAST_fasta.coor.csv", col_names = F)
 #  

```


We can then use the BLASTn tool to blast the fasta assembly.
Note that I couldn't get this installed on alpine, so I installed it on my ovis account. 


```{sh eval=FALSE, include=FALSE}

#To use the command line tool Blast+ from NCBI, follow the instructions outlined for the source tarbal option from the ncbi website 
https://www.ncbi.nlm.nih.gov/books/NBK279671/
#note the make option take ~ 1 hour to run on ovis

#update bash profile to the  c++/ReleaseMT/bin directory 

#now we can use the remote BLAST servers to query multiple fastas

#note that catalog.fa is gziped after populations. need to decompress using gunzip and then change the filename to fasta
#fa is in fasta format. Samtools just won't read it unless it's the right filename

# 
# extract the sequences from the reference catalog with the following bash script, "RDA_snps_fasta.txt"

#!/bin/bash

samtools faidx \
catalog.fasta \
1652:0-350  \
1652:0-350  \
1830:0-350  \
2844:0-350  \
3159:0-350  \
3159:0-350  \
3336:0-350  \
3336:0-350  \
3524:0-350  \
3954:0-350  \
3954:0-350  \
6157:0-350  \
6157:0-350  \
6310:0-350  \
6310:0-350  \
6545:0-350  \
6545:0-350  \
6635:0-350  \
6635:0-350  \
6901:0-350  \
6901:0-350  \
7574:0-350  \
7574:0-350  \
7588:0-350  \
7588:0-350  \
7727:0-350  \
7727:0-350  \
7836:0-350  \
7836:0-350  \
9061:0-350  \
9061:0-350  \
9136:0-350  \
9136:0-350  \
9550:0-350  \
9550:0-350  \
10534:0-350  \
10534:0-350  \
10797:0-350  \
10797:0-350  \
11414:0-350  \
11414:0-350  \
11539:0-350  \
11539:0-350  \
11905:0-350  \
11905:0-350  \
11910:0-350  \
11910:0-350  \
13595:0-350  \
13595:0-350  \
14329:0-350  \
14329:0-350  \
15378:0-350  \
15378:0-350  \
15673:0-350  \
15673:0-350  \
15684:0-350  \
15684:0-350  \
16980:0-350  \
16980:0-350  \
17053:0-350  \
17053:0-350  \
17111:0-350  \
18127:0-350  \
18127:0-350  \
18978:0-350  \
19685:0-350  \
19685:0-350  \
20047:0-350  \
20047:0-350  \
20206:0-350  \
20206:0-350  \
21737:0-350  \
21737:0-350  \
22502:0-350  \
22502:0-350  \
23102:0-350  \
23102:0-350  \
23225:0-350  \
23225:0-350  \
23454:0-350  \
25288:0-350  \
25288:0-350  \
25711:0-350  \
25711:0-350  \
26145:0-350  \
27225:0-350  \
27225:0-350  \
27449:0-350  \
28388:0-350  \
29307:0-350  \
29307:0-350  \
29543:0-350  \
29543:0-350  \
29659:0-350  \
29659:0-350  \
31259:0-350  \
31259:0-350  \
31932:0-350  \
31932:0-350  \
35924:0-350  \
35924:0-350  \
36325:0-350  \
36325:0-350  \
36783:0-350  \
36783:0-350  \
37597:0-350  \
37597:0-350  \
37765:0-350  \
37765:0-350  \
38215:0-350  \
38215:0-350  \
38577:0-350  \
38588:0-350  \
38588:0-350  \
40002:0-350  \
40725:0-350  \
40915:0-350  \
40915:0-350  \
42242:0-350  \
42242:0-350  \
42250:0-350  \
42250:0-350  \
42332:0-350  \
42332:0-350  \
42604:0-350  \
43056:0-350  \
43056:0-350  \
43445:0-350  \
43445:0-350  \
44134:0-350  \
44134:0-350  \
45986:0-350  \
46875:0-350  \
46875:0-350  \
47795:0-350  \
47795:0-350  \
48187:0-350  \
48187:0-350  \
48363:0-350  \
48398:0-350  \
48398:0-350  \
50657:0-350  \
50657:0-350  \
51266:0-350  \
51266:0-350  \
52009:0-350  \
52009:0-350  \
52825:0-350  \
52825:0-350  \
56691:0-350  \
56691:0-350  \
56740:0-350  \
59156:0-350  \
59156:0-350  \
60175:0-350  \
60175:0-350  \
60491:0-350  \
60491:0-350  \
61680:0-350  \
61769:0-350  \
61904:0-350  \
61904:0-350  \
62903:0-350  \
62903:0-350  \
64143:0-350  \
64143:0-350  \
64790:0-350  \
64993:0-350  \
66623:0-350  \
66623:0-350  \
66941:0-350  \
66941:0-350  \
68619:0-350  \
68619:0-350  \
69267:0-350  \
69267:0-350  \
69703:0-350  \
69703:0-350  \
70271:0-350  \
70271:0-350  \
72073:0-350  \
72073:0-350  \
72581:0-350  \
75895:0-350  \
75895:0-350  \
76390:0-350  \
76390:0-350  \
80470:0-350  \
80470:0-350  \
82470:0-350  \
82470:0-350  \
85603:0-350  \
85603:0-350  \
86066:0-350  \
86066:0-350  \
86105:0-350  \
86105:0-350  \
86658:0-350  \
86658:0-350  \
87828:0-350  \
87828:0-350  \
89981:0-350  \
92260:0-350  \
92260:0-350  \
92996:0-350  \
92996:0-350  \
95723:0-350  \
96453:0-350  \
97591:0-350  \
99698:0-350  \
99985:0-350  \
100930:0-350  \
101029:0-350  \
101220:0-350  \
101220:0-350  \
102830:0-350  \
102830:0-350  \
112034:0-350  \
112034:0-350  \
112663:0-350  \
112663:0-350  \
114288:0-350  \
115582:0-350  \
115582:0-350  \
116957:0-350  \
117456:0-350  \
121694:0-350  \
121694:0-350  \
125591:0-350  \
128647:0-350  \
128647:0-350  \
136198:0-350  \
136198:0-350  \
138380:0-350  \
146372:0-350  \
146372:0-350  \
149181:0-350  \
149181:0-350  \
231595:0-350  \
231595:0-350  \
439839:0-350  \
439839:0-350  \
891673:0-350  \
895824:0-350  \
895824:0-350  \
906382:0-350  \
906382:0-350  \
922637:0-350  \
922637:0-350  \
922639:0-350  \
922639:0-350  \
932595:0-350  \
937576:0-350  \
937576:0-350  \
957712:0-350  \
982651:0-350  \
982651:0-350  \
1006295:0-350  \
1029885:0-350  \
1029885:0-350  \
1040364:0-350  \
1077430:0-350  \
1077430:0-350  \
7472:0-350  \
7472:0-350  \
12142:0-350  \
12142:0-350  \
12203:0-350  \
21808:0-350  \
21808:0-350  \
24357:0-350  \
25170:0-350  \
25171:0-350  \
25171:0-350  \
25256:0-350  \
25256:0-350  \
25654:0-350  \
25654:0-350  \
28461:0-350  \
28461:0-350  \
33197:0-350  \
33197:0-350  \
37127:0-350  \
37127:0-350  \
37175:0-350  \
38162:0-350  \
38162:0-350  \
38905:0-350  \
38905:0-350  \
45085:0-350  \
45085:0-350  \
45846:0-350  \
45846:0-350  \
49359:0-350  \
49359:0-350  \
49723:0-350  \
50710:0-350  \
50710:0-350  \
51344:0-350  \
51344:0-350  \
51778:0-350  \
51778:0-350  \
53005:0-350  \
54532:0-350  \
54532:0-350  \
54847:0-350  \
56472:0-350  \
56472:0-350  \
58049:0-350  \
58049:0-350  \
59191:0-350  \
59350:0-350  \
60785:0-350  \
60785:0-350  \
60807:0-350  \
60807:0-350  \
61332:0-350  \
61332:0-350  \
61559:0-350  \
61559:0-350  \
62082:0-350  \
62082:0-350  \
63427:0-350  \
63427:0-350  \
63645:0-350  \
63645:0-350  \
65474:0-350  \
65474:0-350  \
65870:0-350  \
65870:0-350  \
66806:0-350  \
68284:0-350  \
68284:0-350  \
73263:0-350  \
73263:0-350  \
77067:0-350  \
77067:0-350  \
80963:0-350  \
85313:0-350  \
86182:0-350  \
86182:0-350  \
87985:0-350  \
87985:0-350  \
93251:0-350  \
93389:0-350  \
93389:0-350  \
102749:0-350  \
102749:0-350  \
104375:0-350  \
104375:0-350  \
109008:0-350  \
109008:0-350  \
115282:0-350  \
115282:0-350  \
128989:0-350  \
128989:0-350  \
478725:0-350  \
649255:0-350  \
649255:0-350  \
696077:0-350  \
696077:0-350  \
888293:0-350  \
898845:0-350  \
898845:0-350  \
914977:0-350  \
926493:0-350  \
926493:0-350  \
943033:0-350  \
943033:0-350  \
946149:0-350  \
983008:0-350  \
983008:0-350  \
1039390:0-350  \ > blast_fasta_RDA.fasta 


#note that you need to save the above scripts as text files and then read into correns and get rid of the DOS line breaks using 
##    tr -d '\r' < blast_fasta_RDA.txt > blast_fasta_RDA.sh

#can then just run the scripts locally. 

#then submit the list using the BLAST+ software. One of the command line options is “-remote”, which sends the search to NCBI BLAST servers, avoiding the need to install and maintain local databases.
#use “nr/nt” database and with setting parameters max target sequences to 100, expect thresholds to 10 (default), word size to 28 (default) and max matches in a query to 1. We considered a locus homologous if the e‐value returned was smaller than 1.0 e−10.


#Use script Blast_pcadapt.sh

#!/bin/bash
#SBATCH --job-name=mysis_Blast
#SBATCH --output=./mysis_Blast.out
#SBATCH --error=./mysis_Blast.err
#SBATCH --mail-user=Rebecca.G.Cheek@gmail.com
#SBATCH --mail-type=END
#SBATCH --ntasks=1

/home/rgcheek/bin/ncbi-blast-2.13.0+-src/c++/ReleaseMT/bin/blastn -query ./blast_fasta_RDA.fasta -db nt -remote -max_target_seqs 100 -max_hsps 1 -outfmt "7 delim=, qseqid sacc evalue bitscore qcovus pident" -out ./blast_RDA_annotation

```

Same thing for the PCAdapt outliers


```{sh eval=FALSE, include=FALSE}

#To use the command line tool Blast+ from NCBI, follow the instructions outlined for the source tarbal option from the ncbi website 
https://www.ncbi.nlm.nih.gov/books/NBK279671/
#note the make option take ~ 1 hour to run on ovis

#update bash profile to the  c++/ReleaseMT/bin directory 

#now we can use the remote BLAST servers to query multiple fastas

#note that catalog.fa is gziped after populations. need to decompress using gunzip and then change the filename to fasta
#fa is in fasta format. Samtools just won't read it unless it's the right filename

# 
# extract the sequences from the reference cataloug with the following bash script, "pcadapt_snps_fasta.sh"

#!/bin/bash

samtools faidx \
catalog.fasta \
510523:0-350  \
881572:0-350  \
1085313:0-350  \
2057859:0-350  \
2295446:0-350  \
2889604:0-350  \
5813435:0-350  \ > blast_fasta_pcadapt.fasta 


#note that you need to save the above scripts as text files and then read into correns and get rid of the DOS line breaks using 
##    tr -d '\r' < blast_fasta_pcadapt.txt > blast_fasta_pcadapt.sh

#can then just run the scripts locally. 

#then submit the list using the BLAST+ software. One of the command line options is “-remote”, which sends the search to NCBI BLAST servers, avoiding the need to install and maintain local databases.
#use “nr/nt” database and with setting parameters max target sequences to 100, expect thresholds to 10 (default), word size to 28 (default) and max matches in a query to 1. We considered a locus homologous if the e‐value returned was smaller than 1.0 e−10.


#Use script Blast_pcadapt.sh

#!/bin/bash
#SBATCH --job-name=mysis_Blast_pcadapt
#SBATCH --output=./mysis_Blast_pcadapt.out
#SBATCH --error=./mysis_Blast_pcadapt.err
#SBATCH --mail-user=Rebecca.G.Cheek@gmail.com
#SBATCH --mail-type=END
#SBATCH --ntasks=1

/home/rgcheek/bin/ncbi-blast-2.13.0+-src/c++/ReleaseMT/bin/blastn -query ./blast_fasta_pcadapt.fasta -db nt -remote -max_target_seqs 100 -max_hsps 1 -outfmt "7 delim=, qseqid sacc evalue bitscore qcovus pident" -out ./blast_pcadapt_annotation

```

Extract the annotation information for the outliers detected by PCAdapt and the RDA and assemble them all into a pretty table
```{r}
 #none of the outliers detected by PCADAPT were in genes, so will skip it

#####
#the RDA results
#####

RDA.ann <- read.delim("C:/Users/Rebecca/Colostate/GhalamborLab - Documents/Group Projects/mysis/data/redo_sans_jumbo/pre_filter/filtered_data/imputed_data/adaptive_snps/blast_RDA_annotation", header = F, sep = ",", quote = "\"", comment.char = "#")

colnames(RDA.ann) <- c("query_id", "subject_accession", "evalue", "bit_score", "percent_query_coverage_per_uniq_subject", "percent_identity")

## define a helper function
empty_as_na <- function(x){
    if("factor" %in% class(x)) x <- as.character(x) ## since ifelse wont work with factors
    ifelse(as.character(x)!="", x, NA)
}


#Use the R packages mygene and biomaRt to get go terms and functional information for each acession number
#Get the entrez id's from mygene to get the annotation and go terms to merge 

out <- as_tibble(mygene::queryMany(RDA.ann$subject_accession, scopes=c("symbol", "reporter","accession"), fields=c("entrezgene","uniprot")))

RDA.ann$entrezgene_id <- out$entrezgene

#get the gene names
gene_test <- as_tibble(mygene::getGenes(as.list(RDA.ann$entrezgene_id)))

RDA.ann$gene_name <- gene_test$name

#clean up the snp Position information

RDA.ann <- separate(RDA.ann,query_id, c("SNP_Position", "start", "end"))

RDA.ann <-RDA.ann %>% 
  dplyr::select(-(c(start, end))) 

#remove duplicates 

RDA.ann <-unique(RDA.ann)

#write a csv of the results and just look up the go terms 

#write.csv(RDA.ann,"C:/Users/Rebecca/Colostate/GhalamborLab - Documents/Group Projects/mysis/data/redo_sans_jumbo/pre_filter/filtered_data/imputed_data/adaptive_snps/blast_RDA_annotation.csv", row.names = F )

```


We can also run a DAPC to maximize the differences between all adaptive loci

```{r}

mysisvcfr <- read.vcfR("C:/Users/Rebecca/Colostate/GhalamborLab - Documents/Group Projects/mysis/data/redo_sans_jumbo/pre_filter/filtered_data/imputed_data/adaptive_snps/mysis_adaptive_snps.vcf")

mysis_genind <-vcfR2genind(mysisvcfr) #221 variants 


genfile <- as.data.frame(mysis_genind)


#Import the environmental data with the locality information, but filter out the individuals that were removed during filtering  

env <- read.csv("C:/Users/Rebecca/Colostate/GhalamborLab - Documents/Group Projects/mysis/data/mysis_env_final.csv")

env$Lake_name <- as.factor(env$Lake_name) 

#make sure the factor levels are correct
env <- env %>% 
  mutate(Lake_name = recode_factor(Lake_name,"Clear_Water"= "Clearwater", "Lower_Twin"="Lower Twin")) 
 

#order the pred file so that it matches with the genetic data 
#first extract the rownames form the genfile

env <- env[order(match(env[,1], rownames(genfile))),]


#make sure the order of the phenotype and the genetic data are the same
identical(env$individual_id, rownames(genfile))


#Need to first assign all individuals to the correct population

mysis_genind@pop <- as.factor(env$Lake_name) 


## population values read in correctly?
summary(mysis_genind@pop)

####### A. Use cross-validation to determine how many PCs to retain ####### 
# This checks how many PCs should be retained as the number of PCs directly impacts the DAPC results
xval <- xvalDapc(tab(mysis_genind, NA.method="mean"), pop(mysis_genind), parallel = "multicore", ncpus = 4)

####### B. Use the results from Part D to focus in on how many PCs to retain. Analyze the PCs surrounding the peak in proportion of successful outcome prediction from DAPC cross-validation plot. ####### 
# Here, we see the peak at 20 PCs so will run using 20-80  PC axes. So, we re-run xvalDAPC with more repetitions around these PC values 

system.time(xval<-xvalDapc(tab(mysis_genind, NA.method="mean"), pop(mysis_genind), n.pca=20:80, n.rep=100, parallel="multicore", ncpus=4))

####### C. Review the results ####### 
xval[-1] ## retained 20 PCs & 7 discriminant functions saved

# $n.pca: 20 first PCs of PCA used
# $n.da: 7 discriminant functions saved
# $var (proportion of conserved variance): 0.503


#### D. Plot results 

#first read the dapc results as a new data frame

dapc_results <- xval


#custom color pallet
myCol3 <- c("#ff7f00","#1f78b4","#ffff33","#a6cee3","#33a02c", "#C273F9", "#F973CA", "#17A589") # 8 colors for our Lakes 

## With labels to identify clusters by region
scatter(dapc_results$DAPC,posi.da="bottomright", bg="white",cstar=0, col=myCol3, scree.pca=FALSE)


#extract the values from the DAPc model

myssi_dapc <- dapc_results$DAPC

#make sure hte factor level of the lakes in the DAPC results match the labels

dapc_results$DAPC$grp <- factor(dapc_results$DAPC$grp , levels=c("Carter", "Clearwater", "Dillon","Grand", "Gross", "Jefferson", "Lower Twin", "Ruedi"))


lakes<-c(c("Carter", "Clearwater", "Dillon","Grand", "Gross", "Jefferson", "Lower Twin", "Ruedi"))

## With labels for better figure
scatter(dapc_results$DAPC, cex=1.5, legend=T, txt.leg=lakes, clabel=FALSE, posi.leg="topright", posi.da="bottomright", bg="white",cstar=0, col=myCol3, scree.pca=FALSE, cleg = 0.75, xax = 1, yax = 2, inset.solid = 1)


scatter(dapc_results$DAPC, cex=2.5, legend=FALSE, txt.leg=lakes, clabel=FALSE, posi.leg=NA, posi.da="bottomright", bg="white",cstar=0, col=myCol3, scree.pca=FALSE, cleg = 0.75, xax = 1, yax = 2, inset.solid = 1)

## results suggest Gross morphs are grouped together, Clearwater is separate from other lakes on DA2


```


