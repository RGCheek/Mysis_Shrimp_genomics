---
title: "003-Identification_of_Population_Structure_Associated_with_Habitat"
author: "Rebecca Cheek"
date: "2/28/2021"
output: html_document
---


```{r include=FALSE}

#clear memory 

gc()

#Load Libraries

library(tidyverse)
library(pcadapt)
library(qvalue)
library(tidyverse)
library(pegas)
library(ade4)
library(LEA)
library(adegenet)
library(spdep)
library(hierfstat)
library(PopGenReport)
library(ggthemes)
library(mmod)
library(spdep)
library(MASS)
library("poppr")
library("pegas")
library("ape")
library(geodist)
library(vcfR)
library(vegan)
library(reshape2)
library(ggpubr)
library(lme4)
library(MuMIn)
library(gdata)
library(raster)
library(sp)
library(sf)
library(tigris)
library(ggthemes)
library(ggspatial)
library(psych)
library(viridis)
library("ggnewscale")
library(cowplot)
library(maptools)
library(rgdal)
library(gridExtra)
library(RColorBrewer)
library(raster)
library(rgdal)
library(RColorBrewer)


set.seed(666)


```


**PCAdapt** 
	**Description**: PCAdapt uses Principal Components Analysis (PCA) to identify loci showing strong signatures of selection relative to neutral background genomic variation. Here, we will identify putatively adaptive outlier loci using a false discovery rate of 10% and filter these outliers out for downstream landscape genomic analyses to avoid confounding neutral demographic patterns with patterns generated by loci under selection.


```{r message=FALSE, warning=FALSE}

file<-"C:/Users/Rebecca/Colostate/GhalamborLab - Documents/Group Projects/mysis/data/filtered_data/imputed_data/mysis_clean_imputed.ped"


mysis.pcadapt <- read.pcadapt(file,type="ped")


#Choose the appropriate K value from scree plot, run PCAdapt, and get summary.
#it looks like K=1 is the most supported (see results) so we will use that criterion for detecting loci under selection


 y <- pcadapt(mysis.pcadapt, K=5) 
 plot(y,option="screeplot") 
 
#The ‘scree plot’ displays in decreasing order the percentage of variance explained by each PC. Up to a constant, it corresponds to the eigenvalues in decreasing order. The ideal pattern in a scree plot is a steep curve followed by a bend and a straight line. The eigenvalues that correspond to random variation lie on a straight line whereas the ones that correspond to population structure lie on a steep curve. We recommend to keep PCs that correspond to eigenvalues to the left of the straight line (Cattell’s rule).
 
 #in this case, It's hard to tell if K=2 or K=n-1 (so 1) should be used. Based on the snmf results, it seems like K=1 is the best choice. Especially because there is very little variance being explained. 

x <- pcadapt(mysis.pcadapt,K=1)

summary(x)


#A Manhattan plot displays log10 of the p-values.

plot(x,option="manhattan")

#Check the distribution of the p-values using a Q plot, showing the top 5% lowest p-values.

plot(x,option="qqplot",threshold=0.05)

#Use q histogram of p-values to confirm that most of the p-values follow the uniform distribution,
#and that there is an excess of small p-values indicating the presence of outliers.

hist(x$pvalues,xlab="p-values",main=NULL,breaks=50)

#For a given ± (number between 0 and 1), SNPs with q-values less than alpha will be considered outliers with an expected false discovery rate bounded by Î±. 
#The false discovery rate is defined as the percentage of false discoveries expected among the list of outlier candidate SNPs.


qval <- qvalue(x$pvalues)$qvalues

#provide a list of candidate SNPs with an expected false discovery rate less than 10%.
alpha <- 0.10
outliers <- which(qval<alpha)
outliers <- as_tibble(outliers, quote=F)

#Looks like we have 69 potential outliers using our full dataset of 17,012 SNPs

#note that PCAdapt outputs the "order" of the loci rather than the IDs of the loci themselves
# So we will use this output of PCAdapt to filter the loci out of the vcf so we know which SNP the are 

#read back in the "clean" raw file of the snps that passed QC in Plink. The collumns are the snp name with LocusID_Col which can be used to generate a whitelist of snps for neutral populations in Stacks

gen <- read.PLINK("C:/Users/Rebecca/Colostate/GhalamborLab - Documents/Group Projects/mysis/data/filtered_data/imputed_data/mysis_clean_imputed.raw", parallel = F)

gen <- as_tibble(gen)

dim(gen)

#create a sequence from 1 to limit of the vcf so the collumns has numbers that can be filtered out using the list from pcadapt
col_id <- as_tibble(seq(1,34024,1))


col_id$snp =  colnames(gen)

#now we can join to see which are the outlier snps
pcaadapt.outliers <- left_join(outliers,col_id, by="value")

##select just the snp name 

pcaadapt.outliers <- pcaadapt.outliers %>% 
  dplyr::select(snp) 

#read in the snp pos informationf romt he original vcf 
snp_pos <- read.table("C:/Users/Rebecca/Colostate/GhalamborLab - Documents/Group Projects/mysis/data/filtered_data/imputed_data/mysis_clean_imputed_snp_pos.txt")

colnames(snp_pos) <-c("CHROM", "POS", "snp")

dim(snp_pos)


#select the col and pos information from the snp id and make a blacklist 

#the SNP IDs are from the Raw file which includes the genotype. 
pcaadapt_snps<-separate(pcaadapt.outliers, col = snp, into = c("left", "right","genotype"), sep = "_") 


pcaadapt_snps$snp <- paste0(pcaadapt_snps$left, "_", pcaadapt_snps$right)

pcaadapt_snps <- pcaadapt_snps %>% 
  dplyr::select("snp")

blacklist <- left_join(pcaadapt_snps, snp_pos, by="snp")

blacklist <- blacklist %>% 
  dplyr::select("CHROM", "POS")


#write blacklist to make sure these FST outliers are not in neutral data 

# pgirmess::write.delim(blacklist, file = "C:/Users/Rebecca/Colostate/GhalamborLab - Documents/Group Projects/mysis/data/filtered_data/mysis_pcadapt_blacklist.txt", quote = FALSE, row.names = FALSE, sep = "\t",col.names = FALSE )


```


RDA_habitat
		Description: Redundancy analysis implemented with the LEA R package to test multiple loci simultaneously for genetic associations with habitat (Elevation and max lake depth) using constrained orthogonal axes. Because the mysis shrimp were sampled from lakes with the same environmental information, then we will need to do a group based approach where we will use allele frequencies for our RDA instead of the individual genotypes.For the population level RDA, we can  read in our allele frequency data and test to see how different the results are from the individual based RDA. 
		We chose RDA because ther is ver little population structure according to snmf results and our PCA. 
```{r}

#read in the genepop file output from populations
gen <- read.PLINK("C:/Users/Rebecca/Colostate/GhalamborLab - Documents/Group Projects/mysis/data/filtered_data/imputed_data/mysis_clean_imputed.raw", parallel = F)

#RDA require complete data frames (i.e., no missing genetic data). 
#convert to a data frame
gen.imp <- as.data.frame(gen)

#Import the environmental data with the locality information, but filter out the individuals that were removed during filtering  

env <- read.csv("C:/Users/Rebecca/Colostate/GhalamborLab - Documents/Group Projects/mysis/data/mysis_env.csv")

#order the pred file so that it matches with the genetic data 

env <- env[order(match(env$individual_id, rownames(gen.imp))),]

# Confirm that genotypes and environmental data are in the same order

identical(row.names(gen.imp), env$individual_id)

#convart to a genind object 
gen.imp <- as.genind(gen.imp)

#can now convert genind to genepop using the popualiton IDs (lake name) from the environemtnal data. 
gen <- genind2genpop(gen.imp, pop=as.factor(env$Lake_name))

 
#convert to a data frame
gen.imp <- as.data.frame(gen)

genfile <- as.data.frame(gen.imp)

genfile <- as.matrix(genfile, row.names =FALSE, col.names=FALSE)

mode(genfile) <- "numeric"

#select the environmental variables that we have the strongest a priori hypotheses for regarding selection in the shrimp
#according to our local experts, elevation and max lake depth are the predictors that are the most stable throughout the year, so we will use those 
#filter the Clear Water Individuals out of environmental data since it's all NAs and can't run in the RDA

env$Lake_name <- as.factor(env$Lake_name)

#Select just the lake names and the filter to just the unique lakes 

#select just the unique Lake names 

pred <- env[!duplicated(env$Lake_name),] 

pred <- pred %>%
  dplyr::select(c("elevation.meters_above_sea_level", "max_depth_meters"))


pairs.panels(pred, scale=T)  #they are only -.34 correlated so well under out .7 cutoff

#make sure all environmental variables are numeric
pred$elevation.meters_above_sea_level <- as.numeric(pred$elevation.meters_above_sea_level)
pred$max_depth_meters <- as.numeric(pred$max_depth_meters)

#Run the RDA  
mysis.rda<- vegan::rda(genfile ~ elevation.meters_above_sea_level+
                        max_depth_meters , data=pred, scale=T)

summary(mysis.rda)

# 
# Biplot scores for constraining variables
# 
#                                     RDA1   RDA2 PC1 PC2 PC3 PC4
# elevation.meters_above_sea_level  0.9408 0.3390   0   0   0   0
# max_depth_meters                 -0.6978 0.7163   0   0   0   0


#check to see how much of the variation is explained by the model in the R2, and how well the eigenvalues account for the explained variance
vegan::RsquareAdj(mysis.rda) #r2=0.2702736, adjusted r2=-0.0216169

summary(eigenvals(mysis.rda, model = "constrained"))
# 
# Importance of components:
#                            RDA1      RDA2
# Eigenvalue            4872.6632 4276.9106
# Proportion Explained     0.5326    0.4674
# Cumulative Proportion    0.5326    1.0000

#We can visualize this information using a screeplot of the canonical eigenvalues by calling `screeplot`:

screeplot(mysis.rda) #RDA 1 explains a bit more of the variance


# signif.full <- anova.cca(mysis.rda, parallel=getOption("mc.cores"), model="full", permutation=99999) 
# signif.full 
# Permutation test for rda under full model
# Permutation: free
# Number of permutations: 999
# 
# Model: rda(formula = genfile ~ elevation.meters_above_sea_level + max_depth_meters, data = pred, scale = T)
#          Df Variance      F Pr(>F)
# Model     2   8576.7 1.0156  0.467
# Residual  6  25335.3              

#signif.axis <- anova.cca(mysis.rda, by="axis", parallel=getOption("mc.cores"), permutation=99999)
#signif.axis

# Permutation test for rda under reduced model
# Forward tests for axes
# Permutation: free
# Number of permutations: 999
# 
# Model: rda(formula = genfile ~ elevation.meters_above_sea_level + max_depth_meters, data = pred, scale = T)
#          Df Variance      F Pr(>F)
# RDA1      1   4833.0 1.1446  0.422
# RDA2      1   3743.6 0.8866  0.702
# Residual  6  25335.3              
# 

#signif.terms <- anova.cca(mysis.rda, by="terms", parallel=getOption("mc.cores"), permutation=99999)
#signif.terms
# 
# Model: rda(formula = genfile ~ elevation.meters_above_sea_level + max_depth_meters, data = pred, scale = T)
#          Df Variance      F Pr(>F)
# RDA1      1   4833.0 1.1446  0.422
# RDA2      1   3743.6 0.8866  0.702
# Residual  6  25335.3              

#checking Variance Inflation Factors for the predictor variables used in the model:

vegan::vif.cca(mysis.rda) 

#All values are less than 2, so collinarity shouldn't be a problem. 

#quick plot of the RDA output using the default plotting in `vegan`

plot(mysis.rda, scaling=3)          # default is axes 1 and 2

###### To highlight individuals by lake

#custom color pallett

myCol2 <- c("#ff7f00","#1f78b4","#ffff33","#a6cee3","#33a02c", "#C273F9", "#F973CA", "#17A589","#e31a1c" ) # 9 colors for our Lakes plus 2 phenotypes

#9 nice colors for our Lakes plus 2 phenotypes

#Extract the scores from the rda
#Be sure to scale everyting symmetrically by using the scaling=3 argument which will scale based on the sqare root of the eigenvalues
mysis_sam_sco <- scores(mysis.rda, display = "sites", scaling=3)
mysis_env_sco <- scores(mysis.rda, display = "bp", scaling=3)
mysis_sam_tbl <- as_tibble(mysis_sam_sco)
mysis_env_tbl <- as_tibble(mysis_env_sco)
mysis_sam_tbl <- mutate(mysis_sam_tbl, mysis_sam_sco,
                       ccatype = "sites")
mysis_sam_tbl <- cbind(pred, mysis_sam_tbl)
mysis_env_tbl <- mutate(mysis_env_tbl, vgntxt=rownames(mysis_env_sco),
                       ccatype = "bp")


#extract the loading scores of the snps 

mysis_spp_sco <- scores(mysis.rda, display = "species", scaling=3)
mysis_spp_tbl <- as_tibble(mysis_spp_sco)
mysis_spp_tbl <- mutate(mysis_spp_tbl, vgntxt=rownames(mysis_spp_sco),
                       ccatype = "species")


Lakes <- as_tibble(unique(env$Lake_name))

Lakes <- Lakes %>% 
  mutate(value = recode_factor(value,"Lower_Twin"="Lower Twin","GGross"="Gross (Giant)","RGross"="Gross (Regular)", "Clear_Water"="Clearwater"))

mysis_sam_tbl$Lake_name <- factor(Lakes$value, 
  levels=c(c("Carter","Clearwater", "Dillon","Grand", "Gross (Giant)", "Gross (Regular)", "Jefferson", "Lower Twin", "Ruedi")))


#Plot the individuals on axis 1 &2 

plot(mysis.rda, type="n", choices=c(1,2))
points(mysis.rda, display="species", pch=20, cex=0.7, col="gray32")          # the SNPs
points(mysis.rda, display="sites", pch=21, cex=1.3, col="gray32", bg=myCol2[mysis_sam_tbl$Lake_name]) # the shrimp
text(mysis.rda, display="bp", col="#0868ac", cex=1)   # the predictors
legend("bottomright", legend=levels(mysis_sam_tbl$Lake_name), bty="n", col="gray32", pch=21, cex=1, pt.bg = myCol2)



#with ggplot 
rda_plot_12 <- ggplot() +
     #geom_point(data=mysis_spp_tbl, aes(x=RDA1,y=RDA2), col="gray32")  +        # the SNPs
  geom_point(data=mysis_sam_tbl,aes(x=RDA1,y=RDA2, fill=Lake_name), shape=21,color="black", size=6) +# the shrimp
 scale_fill_manual(name="Lake Name", values=myCol2, guide= "none")+
  geom_hline(yintercept = 0, lty = 2) +
      geom_vline(xintercept = 0, lty = 2) +
    theme_few()+
     geom_segment(data = mysis_env_tbl, aes(x = 0, y = 0, xend = (RDA1*2),
     yend = (RDA2*2)), arrow = arrow(length = unit(1/2, "picas")),
     color = "black", size=1.2) + #plot the predictors 
 annotate("text", x = (mysis_env_tbl$RDA1*6), y = (mysis_env_tbl$RDA2*4),
            label =c("Elevation", "Max Depth"), color="black", size=5)+
    xlab("RDA1") + ylab("RDA2\n") +
  theme(
     # legend.position =c(.17,.95),
     #     legend.justification = c("right", "top"),
     # legend.title = element_text(size=12, face="bold"),
        legend.text = element_text(size=12, face="bold"),
        axis.title=element_text(colour="black", size = 15,face="bold"),
     axis.text=element_text(colour="black", size = 13,face="bold"))


rda_plot_12

```

We can now see if there are any outlier loci that could be associated with our environmental variables, and then use a PCA to see individual variation at those loci. 


```{r}
##########################################
# Identify candidate SNPs
#
##########################################
#Use the loadings of the SNPs (their location) in the ordination
#space to determine which SNPs are candidates for local adaptation.
#The SNP loadings are stored as `species` in the RDA object. We'll extract the SNP loadings from the 2 constrained axes (since we only have 2 predictors):

load.cca <- scores(mysis.rda, choices=c(1:2), display="species")

#If we look at histograms of the loadings on each RDA axis,
#we can see their (relatively normal) distribution. SNPs loading at the center of the distribution are not showing
#a relationship with the environmental predictors; those loading in the tails are, and are more #likely to be under selection as a function of those predictors (or some other predictor correlated with them).


hist(load.cca[,1], main="Loadings on RDA1")
hist(load.cca[,2], main="Loadings on RDA2")



#define the function here as `outliers`, where `x` is the vector of loadings and `z` is the number of standard deviations to use:

#find loadings +/-z sd from mean loading
#locus names of the tails

outliers <- function(x,z){
  lims <- mean(x) + c(-1, 1) * z * sd(x)       
  x[x < lims[1] | x > lims[2]]           
}


#using an sd of 2.5 for moderate selection 

cand1 <- outliers(load.cca[,1],2.5) # 59
cand2 <- outliers(load.cca[,2],2.5) # 135



ncand <- length(cand1)+length(cand2) 
ncand


# 2333 if using  weak selection cutoff of 2 sd from the mean

#make a single data frame with the axis, SNP name, & loading:

cand1 <- cbind.data.frame(rep(1,times=length(cand1)), names(cand1), unname(cand1))
cand2 <- cbind.data.frame(rep(2,times=length(cand2)), names(cand2), unname(cand2))


colnames(cand1) <- colnames(cand2) <- c("axis","snp","loading")


cand <- rbind(cand1, cand2)

cand$snp <- as.character(cand$snp)

foo <- matrix(nrow=(ncand), ncol=2)  # 2 columns for 2 predictors

colnames(foo) <- c( "elevation.meters_above_sea_level", "max_depth_meters")

pred <- pred %>% 
  dplyr::select(c( "elevation.meters_above_sea_level",  "max_depth_meters"))


for (i in 1:length(cand$snp)) {
  nam <- cand[i,2]
  snp.gen <- genfile[,nam]
  foo[i,] <- apply(pred,2,function(x) cor(x,snp.gen))
}

cand <- cbind.data.frame(cand,foo)  
head(cand)

dim(cand) #173

#Some of these may be duplicate detections; let's check:


# duplicate detections:
length(cand$snp[duplicated(cand$snp)])
foo <- cbind(cand$axis,duplicated(cand$snp))
table(foo[foo[,1]==1,2])
table(foo[foo[,1]==2,2])


cand <- cand[!duplicated(cand$snp),] #remove duplicates

dim(cand) # final tally is 194


#which predictor each snp is more correlated with

for (i in 1:length(cand$snp)) {
  bar <- cand[i,]
  cand[i,6] <- names(which.max(abs(bar[3:5]))) # gives the variable
  cand[i,7] <- max(abs(bar[3:5]))              # gives the correlation
}

colnames(cand)[6] <- "predictor"
colnames(cand)[7] <- "correlation"

table(cand$predictor)

#for 2.5 sd cutoff
# elevation.meters_above_sea_level 
#                               53 
#                 max_depth_meters 
#                              141 

##To highlight SNPs of just our predictors


sel <- cand$snp
eco <-cand$predictor

eco[eco =="elevation.meters_above_sea_level"] <- '#f2853d'
eco[eco =="max_depth_meters"] <- '#3498DB'

# color by predictor:
col.pred <- rownames(mysis.rda$CCA$v) # pull out all the SNP names


for (i in 1:length(sel)) {           # color code candidate SNPs
  foo <- match(sel[i],col.pred)
  col.pred[foo] <- eco[i]
}

colors <- c("#f2853d","#3498DB")

col.pred[!grepl(paste(colors,collapse="|"), col.pred)] <- '#f1eef6' # non-candidate SNPs assigned transparent color
empty <- col.pred

empty[grep("#f1eef6",empty)] <- rgb(0,1,0, alpha=0) # transparent
empty.outline <- ifelse(empty=="#00FF0000","#00FF0000","gray32")

#Color the depth and elevation snps
bg <- c(c("#f2853d","#3498DB"))


# axes 1 & 2 basic plot

plot(mysis.rda, type="n", scaling=3, xlim=c(-1,1), ylim=c(-1,1))
points(mysis.rda, display="species", pch=21, cex=1, col="grey32", bg=col.pred, scaling=3)
points(mysis.rda, display="species", pch=21, cex=1,col=empty.outline, bg=empty, scaling=3)
text(mysis.rda, scaling=3, display="bp", col="#0868ac", cex=1)
legend("topright",legend=c("Elevation", "Max Depth"), bty="n", col="gray32", pch=21, cex=1, pt.bg=bg)

#extract the loading scores of the snps
mysis_spp_sco <- scores(mysis.rda, display = "species", scaling=3)
mysis_spp_tbl <- as_tibble(mysis_spp_sco)
mysis_spp_tbl_median<- mutate(mysis_spp_tbl, vgntxt=rownames(mysis_spp_sco),
                       ccatype = "species")

mysis_spp_tbl$colors <- col.pred

#select just the neutral snps and plot those first in ggplot
mysis_spp_neutral <- mysis_spp_tbl %>% 
  filter(colors=="#f1eef6")

#select out the neutral snps to get the adaptive snps 
mysis_spp_tbl <- mysis_spp_tbl %>% 
  filter(!colors=="#f1eef6")


rda_plot_snps <- ggplot()+
   geom_point(data=mysis_spp_neutral, aes(x=RDA1,y=RDA2), col="grey40", size =2)  +  # the neutral SNPs
       geom_point(data=mysis_spp_tbl, aes(x=RDA1,y=RDA2, color=colors), size=2) + 
        scale_color_manual(values=c("#f2853d","#3498DB"),  name="", labels = c("Elevation", "Max Lake Depth"))+
  #transparent outlines so you can see all the outlier snps over the neutral ones
  geom_hline(yintercept = 0, lty = 2) +
      geom_vline(xintercept = 0, lty = 2) +
  expand_limits(x = c(-.1, .12), y = c(-0.05, 0.05))+
    theme_few()+
     geom_segment(data = mysis_env_tbl, aes(x = 0, y = 0, xend = (RDA1*.35),
     yend = (RDA2*.35)), arrow = arrow(length = unit(1/2, "picas")),
     color = "black", size=1) + #plot the predictors 
 annotate("text", x = (mysis_env_tbl$RDA1*.5), y = (mysis_env_tbl$RDA2*.5),
              label =c("Elevation", "Max Lake Depth") , color="black", size=5)+
   xlab("RDA1") + ylab("RDA2") +
  theme(legend.position =c(.17,.97),
        legend.justification = c("right", "top"),
    legend.title = element_text(size=10, face="bold"),
        legend.text = element_text(size=10, face="bold"),
        axis.title=element_text(colour="black", size = 15,face="bold"),
     axis.text=element_text(colour="black", size = 13,face="bold"))

rda_plot_snps


```


Check to see how many of the SNPs are shared between the RDA and PCAdapt 


```{r}

#make a large list of SNPs

RDA_snps <- cand %>% 
  dplyr::select(snp)

all_outliers <- rbind(RDA_snps, pcaadapt.outliers)


snp.list <- separate(all_outliers, snp ,
                     c("Locus ID", "Col", "gen"))

snp.list <- snp.list %>% 
  dplyr::select(c("Locus ID", "Col"))

#keep only the unique loci and col
snp.list <- distinct(snp.list)

dim(snp.list) #184 total candidate loci



#from the RDA?
RDA_snps <- cand

RDA_snps <- separate(RDA_snps, snp ,
                     c("Locus ID", "Col", "gen"))

RDA_snps<- RDA_snps [!duplicated(RDA_snps[c("Locus ID", "Col")]),]


dim(RDA_snps) # 124 total candidate loci from the RDA

table(RDA_snps$predictor)

#how many unique loci from the pcadapt?
pcaadapt_snps <- separate(pcaadapt.outliers, snp ,
                     c("Locus ID", "Col", "gen"))

pcaadapt_snps <- pcaadapt_snps %>% 
  dplyr::select(c("Locus ID", "Col"))

#keep only the unique loci and col
pcaadapt_snps <- distinct(pcaadapt_snps)

dim(pcaadapt_snps) # 69 total candidate loci pcadapt

#between the RDA and PCAdapt, how many lici are shared? 

overlap_snps <- semi_join(pcaadapt_snps, RDA_snps, by=c("Locus ID", "Col")) #no overlaps


#the SNP IDs are from the Raw file which includes the genotype. 
whitelist <-separate(all_outliers, col = snp, into = c("left", "right","genotype"), sep = "_") 


whitelist$snp_id <- paste0(whitelist$left, "_", whitelist$right)

#get the col pos and snp id from the original vcf

pos_snp <- read.table("C:/Users/Rebecca/Colostate/GhalamborLab - Documents/Group Projects/mysis/data/filtered_data/imputed_data/mysis_clean_imputed_snps.txt")

colnames(pos_snp) <- c("chrom","pos","snp_id")

whitelist <- left_join(whitelist, pos_snp, by="snp_id")

sum(is.na(whitelist$chrom)) #no Nas so RDA whitelist is ready to use

#Select just the chrom and pos information from the RDA outliers to filter out using vcftools
whitelist <- whitelist %>% 
  dplyr::select(c("chrom", "pos"))

dim(distinct(whitelist)) #184
    
# #write out whitelist to get our full adaptive loci dataset 
# pgirmess::write.delim(whitelist, file = "C:/Users/Rebecca/Colostate/GhalamborLab - Documents/Group Projects/mysis/data/filtered_data/imputed_data/adaptive_snps/mysis_adaptive_snps_all.txt", quote = FALSE, row.names = FALSE, sep = "\t",col.names = FALSE )


#make a seperate whitelist of the RDA candidates 

RDA_snps <- cand %>% 
  dplyr::select(snp)

#the SNP IDs are from the Raw file which includes the genotype. 
whitelist <-separate(RDA_snps, col = snp, into = c("left", "right","genotype"), sep = "_") 


whitelist$snp_id <- paste0(whitelist$left, "_", whitelist$right)

#get the col pos and snp id from the original vcf

pos_snp <- read.table("C:/Users/Rebecca/Colostate/GhalamborLab - Documents/Group Projects/mysis/data/filtered_data/imputed_data/mysis_clean_imputed_snps.txt")

colnames(pos_snp) <- c("chrom","pos","snp_id")

whitelist <- left_join(whitelist, pos_snp, by="snp_id")

sum(is.na(whitelist$chrom)) #no Nas so RDA whitelist is ready to use

#Select just the chrom and pos information from the RDA outliers to filter out using vcftools
whitelist <- whitelist %>% 
  dplyr::select(c("chrom", "pos"))

dim(distinct(whitelist)) #115

#make a whitelist for the RDA SNPS
# pgirmess::write.delim(whitelist, file = "C:/Users/Rebecca/Colostate/GhalamborLab - Documents/Group Projects/mysis/data/filtered_data/imputed_data/adaptive_snps/mysis_adaptive_snps_RDA.txt", quote = FALSE, row.names = FALSE, sep = "\t",col.names = FALSE )



```


Since we used population-based RDA of candidate markers to identify drivers of adaptive divergence, we can use an individual-based PCA to investigate adaptive differentiation.


Filter to just the "adaptive SNPs" from RDA from the full vcf using bcftools and vcftools.  

```{sh}

#get the positional information from the original imputed VF
bcftools query -f '%CHROM\t%POS\t%ID\n' mysis_clean_imputed.vcf > mysis_clean_imputed_snps.txt

#filter to just the RDA SNPs
vcftools --vcf ./mysis_clean_imputed_names_fix.vcf --positions ./mysis_adaptive_snps_RDA.txt --recode --recode-INFO-all --out ./adaptive_snps/mysis_adaptive_snps_RDA.vcf
 
 #After filtering, kept 124 out of a possible 17012 Sites

```


PCA of just the RDA outliers. Since we can say more about what these outliers are actually associated with, it will be easier to interpret the PCA results. Furthermore, because we generated this list of adative snps from the RDA it will be more informative as to what the model is acctually seeing.  

```{r}

#plot out the imputed snps following filtering and imputation

mysis_gen <- read.PLINK("C:/Users/Rebecca/Colostate/GhalamborLab - Documents/Group Projects/mysis/data/filtered_data/imputed_data/adaptive_snps/mysis_adaptive_snps_RDA.raw", parallel = F)

dim(mysis_gen)

#should be 124 adaptive snps

#read plink reads it in as a genlight but scripts wants a genind so convert to a dataframe and then genind 

gen <-as.matrix(mysis_gen)

mode(gen) <- "numeric"

sum(is.na(gen)) 

#now we can use the rda function from the vegan package which is the same thing as a pca

mysis.pca1 <- rda(gen) #PCA using rda function 


summary(mysis.pca1)$cont 


screeplot(mysis.pca1, main = "Screeplot: Eigenvalues of Predictor Variables") #10 PCs 


#We'll store our synthetic PC axis predictor as pred.PC1 for use in mapping.

pred.PC1 <- scores(mysis.pca1, choices=1, display="sites", scaling=0)


#quick and dirty plot
plot(pred.PC1)

#order the pred file so that it matches with the genetic data 

env <- read.csv("C:/Users/Rebecca/Colostate/GhalamborLab - Documents/Group Projects/mysis/data/mysis_env.csv")

env <- env[order(match(env$individual_id, rownames(gen))),]


#make sure the order of the phenotype and the genetic data are the same
identical(env$individual_id, rownames(gen))


##plot PCA in ordination space
###### To highlight individuals by library 
#custom color pallet
myCol2 <- c("#ff7f00","#1f78b4","#ffff33","#a6cee3","#33a02c", "#C273F9", "#F973CA", "#17A589","#e31a1c" ) # 9 colors for our Lakes plus 2 phenotypes


#Extract the scores from the pca
#Be sure to scale everything symmetrically by using the scaling=3 argument which will scale based on the square root of the eigenvalues
mysis_sam_sco <- scores(mysis.pca1, choices = 1:10, display = "sites")
mysis_sam_tbl <- as_tibble(mysis_sam_sco)
mysis_sam_tbl <- mutate(mysis_sam_tbl, individual_id=rownames(mysis_sam_sco),
                       ccatype = "sites")

mysis_sam_tbl <- left_join(env, mysis_sam_tbl, by="individual_id")


#extract the loading scores of the snps 

mysis_spp_sco <- scores(mysis.pca1, display = "species")
mysis_spp_tbl <- as_tibble(mysis_spp_sco)
mysis_spp_tbl <- mutate(mysis_spp_tbl, vgntxt=rownames(mysis_spp_sco),
                       ccatype = "species")
 

mysis_sam_tbl <- mysis_sam_tbl %>% 
  dplyr::mutate(Lake_name = recode_factor(Lake_name,"Lower_Twin"="Lower Twin","GGross"="Gross (Jumbo)","RGross"="Gross (Regular)", "Clear_Water"="Clearwater"))

mysis_sam_tbl$Lake_name <- factor(mysis_sam_tbl$Lake_name, 
   levels=c("Carter", "Clearwater", "Dillon","Grand", "Gross (Jumbo)", "Gross (Regular)", "Jefferson", "Lower Twin", "Ruedi"))




#with ggplot
pc_plot_12 <- ggplot() +
  geom_point(data=mysis_sam_tbl,aes(x=PC1,y=PC2, fill=Lake_name), shape=21,  color="black", size=4) +# the shrimp
  scale_fill_manual(values = myCol2)+
  geom_hline(yintercept = 0, lty = 2) +
  geom_vline(xintercept = 0, lty = 2) +
  theme_few()+
  xlab("PC Axis 1 (5.19%)") + ylab("PC Axis 2 (3.64%)") +
  theme(
    # legend.position =c(.18,.98),
    #     legend.justification = c("right", "top"),
    #     legend.title = element_text(size=12, face="bold"),
    #     legend.text = element_text(size=12, face="bold"),
        axis.title=element_text(colour="black", size = 15,face="bold"),
        axis.text=element_text(colour="black", size = 13,face="bold"),
        plot.background = element_rect(fill = "transparent",colour = NA))

pc_plot_12

#with ggplot
pc_plot_13 <- ggplot() +
  geom_point(data=mysis_sam_tbl,aes(x=PC1,y=PC3, fill=Lake_name), shape=21,  color="black", size=4) +# the shrimp
  scale_fill_manual(values = myCol2)+
  geom_hline(yintercept = 0, lty = 2) +
  geom_vline(xintercept = 0, lty = 2) +
  theme_few()+
  xlab("PC Axis 1 (5.19%)") + ylab("PC Axis 3 (3.33%)") +
  theme(legend.position =c(.18,.98),
        legend.justification = c("right", "top"),
        legend.title = element_text(size=12, face="bold"),
        legend.text = element_text(size=12, face="bold"),
        axis.title=element_text(colour="black", size = 15,face="bold"),
        axis.text=element_text(colour="black", size = 13,face="bold"),
        plot.background = element_rect(fill = "transparent",colour = NA))

pc_plot_13




#with ggplot
pc_plot_23 <- ggplot() +
  geom_point(data=mysis_sam_tbl,aes(x=PC2,y=PC3, fill=Lake_name), shape=21,  color="black", size=4) +# the shrimp
  scale_fill_manual(values = myCol2)+
  geom_hline(yintercept = 0, lty = 2) +
  geom_vline(xintercept = 0, lty = 2) +
  theme_few()+
  xlab("PC Axis 2 (3.63%)") + ylab("PC Axis 3 (3.33%)") +
  theme(legend.position =c(.18,.98),
        legend.justification = c("right", "top"),
        legend.title = element_text(size=12, face="bold"),
        legend.text = element_text(size=12, face="bold"),
        axis.title=element_text(colour="black", size = 15,face="bold"),
        axis.text=element_text(colour="black", size = 13,face="bold"),
        plot.background = element_rect(fill = "transparent",colour = NA))

pc_plot_23

#with ggplot
pc_plot_34 <- ggplot() +
  geom_point(data=mysis_sam_tbl,aes(x=PC3,y=PC4, fill=Lake_name), shape=21,  color="black", size=4) +# the shrimp
  scale_fill_manual(values = myCol2)+
  geom_hline(yintercept = 0, lty = 2) +
  geom_vline(xintercept = 0, lty = 2) +
  theme_few()+
  xlab("PC Axis 3 (3.33%)") + ylab("PC Axis 4 (3.30%)") +
  theme(legend.position =c(.18,.98),
        legend.justification = c("right", "top"),
        legend.title = element_text(size=12, face="bold"),
        legend.text = element_text(size=12, face="bold"),
        axis.title=element_text(colour="black", size = 15,face="bold"),
        axis.text=element_text(colour="black", size = 13,face="bold"),
        plot.background = element_rect(fill = "transparent",colour = NA))

pc_plot_34

#with ggplot
pc_plot_45 <- ggplot() +
  geom_point(data=mysis_sam_tbl,aes(x=PC4,y=PC5, fill=Lake_name), shape=21,  color="black", size=4) +# the shrimp
  scale_fill_manual(values = myCol2)+
  geom_hline(yintercept = 0, lty = 2) +
  geom_vline(xintercept = 0, lty = 2) +
  theme_few()+
  xlab("PC Axis 4 (3.30%)") + ylab("PC Axis 5 (3.06%)") +
  theme(legend.position =c(.18,.98),
        legend.justification = c("right", "top"),
        legend.title = element_text(size=12, face="bold"),
        legend.text = element_text(size=12, face="bold"),
        axis.title=element_text(colour="black", size = 15,face="bold"),
        axis.text=element_text(colour="black", size = 13,face="bold"),
        plot.background = element_rect(fill = "transparent",colour = NA))

pc_plot_45

#with ggplot
pc_plot_56 <- ggplot() +
  geom_point(data=mysis_sam_tbl,aes(x=PC5,y=PC6, fill=Lake_name), shape=21,  color="black", size=4) +# the shrimp
  scale_fill_manual(values = myCol2)+
  geom_hline(yintercept = 0, lty = 2) +
  geom_vline(xintercept = 0, lty = 2) +
  theme_few()+
  xlab("PC Axis 5 (2.93%)") + ylab("PC Axis 6 (2.93%)") +
  theme(legend.position =c(.18,.98),
        legend.justification = c("right", "top"),
        legend.title = element_text(size=12, face="bold"),
        legend.text = element_text(size=12, face="bold"),
        axis.title=element_text(colour="black", size = 15,face="bold"),
        axis.text=element_text(colour="black", size = 13,face="bold"),
        plot.background = element_rect(fill = "transparent",colour = NA))

pc_plot_56

#with ggplot
pc_plot_67 <- ggplot() +
  geom_point(data=mysis_sam_tbl,aes(x=PC6,y=PC7, fill=Lake_name), shape=21,  color="black", size=4) +# the shrimp
  scale_fill_manual(values = myCol2)+
  geom_hline(yintercept = 0, lty = 2) +
  geom_vline(xintercept = 0, lty = 2) +
  theme_few()+
  xlab("PC Axis 6 (2.93%)") + ylab("PC Axis 7 (2.76%)") +
  theme(legend.position =c(.18,.98),
        legend.justification = c("right", "top"),
        legend.title = element_text(size=12, face="bold"),
        legend.text = element_text(size=12, face="bold"),
        axis.title=element_text(colour="black", size = 15,face="bold"),
        axis.text=element_text(colour="black", size = 13,face="bold"),
        plot.background = element_rect(fill = "transparent",colour = NA))

pc_plot_67

#with ggplot
pc_plot_78 <- ggplot() +
  geom_point(data=mysis_sam_tbl,aes(x=PC7,y=PC8, fill=Lake_name), shape=21,  color="black", size=4) +# the shrimp
  scale_fill_manual(values = myCol2)+
  geom_hline(yintercept = 0, lty = 2) +
  geom_vline(xintercept = 0, lty = 2) +
  theme_few()+
  xlab("PC Axis 7 (2.76%)") + ylab("PC Axis 8 (2.70%)") +
  theme(legend.position =c(.18,.98),
        legend.justification = c("right", "top"),
        legend.title = element_text(size=12, face="bold"),
        legend.text = element_text(size=12, face="bold"),
        axis.title=element_text(colour="black", size = 15,face="bold"),
        axis.text=element_text(colour="black", size = 13,face="bold"),
        plot.background = element_rect(fill = "transparent",colour = NA))

pc_plot_78

#with ggplot
pc_plot_89 <- ggplot() +
  geom_point(data=mysis_sam_tbl,aes(x=PC8,y=PC9, fill=Lake_name), shape=21,  color="black", size=4) +# the shrimp
  scale_fill_manual(values = myCol2)+
  geom_hline(yintercept = 0, lty = 2) +
  geom_vline(xintercept = 0, lty = 2) +
  theme_few()+
  xlab("PC Axis 8 (2.70%)") + ylab("PC Axis 9 (2.56%)") +
  theme(legend.position =c(.18,.98),
        legend.justification = c("right", "top"),
        legend.title = element_text(size=12, face="bold"),
        legend.text = element_text(size=12, face="bold"),
        axis.title=element_text(colour="black", size = 15,face="bold"),
        axis.text=element_text(colour="black", size = 13,face="bold"),
        plot.background = element_rect(fill = "transparent",colour = NA))

pc_plot_89

#with ggplot
pc_plot_910 <- ggplot() +
  geom_point(data=mysis_sam_tbl,aes(x=PC9,y=PC10, fill=Lake_name), shape=21,  color="black", size=4) +# the shrimp
  scale_fill_manual(values = myCol2)+
  geom_hline(yintercept = 0, lty = 2) +
  geom_vline(xintercept = 0, lty = 2) +
  theme_few()+
  xlab("PC Axis 9 (2.56%)") + ylab("PC Axis 10 (2.53%)") +
  theme(legend.position =c(.18,.98),
        legend.justification = c("right", "top"),
        legend.title = element_text(size=12, face="bold"),
        legend.text = element_text(size=12, face="bold"),
        axis.title=element_text(colour="black", size = 15,face="bold"),
        axis.text=element_text(colour="black", size = 13,face="bold"),
        plot.background = element_rect(fill = "transparent",colour = NA))

pc_plot_910

```
We see no evidence of adaptive differentiation in the top 10 PC axes. PC1 and PC2 shows maybe some limited variation between populations,but not clear clustering.


We can now use the snps from the PCAdapt analysis and RDA to see if there are any genes or regions nearby that are associated with hypoxia, or heat shock proteins. 
Based on our LD estimates in section 1, it looks like there is fairly low LD in the shrimp data. So we will just pull the 350 bp consensus sequences from our SNP targets and BLAST them to see if they align to any known genes.  

Extracting positions from the catalog fasta to use in Blast.


```{r}


#option to get positional information from vcf
vcf_pos <- (read.vcfR("C:/Users/Rebecca/Colostate/GhalamborLab - Documents/Group Projects/mysis/data/filtered_data/imputed_data/mysis_clean_imputed.vcf")) 

#extract the positional collumns
vcf_pos <- as.data.frame(vcf_pos@fix)


#add the ref and alternate snps

vcf_pos$REF <- paste0(vcf_pos$ID, "_", vcf_pos$REF)
 
vcf_pos$ALT <- paste0(vcf_pos$ID, "_", vcf_pos$ALT)

#also add a HET snp

vcf_pos$HET <- "HET"
 
vcf_pos$HET <- paste0(vcf_pos$ID, "_", vcf_pos$HET)
 
# Convert the wide data to long
vcf_pos <- gather(vcf_pos, condition, snp, c(REF,ALT,HET), factor_key=TRUE)

vcf_pos <- as_tibble(vcf_pos)
#because we don't have chromosomes all we have is the catalog locus ID which is imbedded int he snp info, so need to extract that 

#make a new collumn that sepperates out position info 

vcf_pos<- tidyr::separate(vcf_pos, col=ID , into=
               c("Locus ID", "Col"), sep="_")

#select just the catalog locus ID, snp and position collumns

vcf_pos <- vcf_pos %>% 
  dplyr::select(c("Locus ID","POS", "snp")) %>% 
  dplyr::rename( "CHROM"="Locus ID")



#merge the RDA cands to the position information

rda.pos.info <- left_join(cand, vcf_pos, by= "snp")

rda.pos.info$POS <- as.numeric(rda.pos.info$POS)

#Subtract and add 350 from the position to get range to extract from genomic fasta to be used for blast searching.

rda.pos.info$pos.min <- 0

rda.pos.info$pos.min[rda.pos.info$pos.min<0] <- 0 #convert negative valuse to zero so it'll just be the start of the file

rda.pos.info$pos.max <- 350

#make a new collumn that sepperates out position info 
rda.pos.info$pos.range <- paste(rda.pos.info$pos.min,rda.pos.info$pos.max, sep="-")


rda.pos.info$sca.snp <- paste(rda.pos.info$CHROM,rda.pos.info$snp, sep=".")

#write a text file with the snp name and position range 
rda.pos.info$fasta.range <- paste(rda.pos.info$CHROM, rda.pos.info$pos.range, sep=":")


rda.blast.info <- as_tibble(rda.pos.info$fasta.range)

# add a backslash to the end of the columns 

rda.blast.info <- as_tibble(paste(rda.blast.info$value, " \\"))
 
# #write csv and then copy paste information into Gemma_snps_fasta.sh below
 # write_csv(rda.blast.info,"C:/Users/Rebecca/Colostate/GhalamborLab - Documents/Group Projects/mysis/data/filtered_data/imputed_data/adaptive_snps/mysis_pop_RDA_BLAST_fasta.coor.csv", col_names = F)
 # 

#do the same thing for the PCAdapt outliers 


#merge the RDA cands to the position information

pcadapt.pos.info <- left_join(pcaadapt.outliers, vcf_pos, by= "snp")

pcadapt.pos.info$POS <- as.numeric(pcadapt.pos.info$POS)

#add 350

pcadapt.pos.info$pos.min <- 0

pcadapt.pos.info$pos.min[pcadapt.pos.info$pos.min<0] <- 0 #convert negative values to zero so it'll just be the start of the file

pcadapt.pos.info$pos.max <- 350

#make a new collumn that sepperates out position info 
pcadapt.pos.info$pos.range <- paste(pcadapt.pos.info$pos.min,pcadapt.pos.info$pos.max, sep="-")


pcadapt.pos.info$sca.snp <- paste(pcadapt.pos.info$CHROM,pcadapt.pos.info$snp, sep=".")

#write a text file with the snp name and position range 
pcadapt.pos.info$fasta.range <- paste(pcadapt.pos.info$CHROM, pcadapt.pos.info$pos.range, sep=":")


pcadapt.pos.info <- as_tibble(pcadapt.pos.info$fasta.range)

# add a backslash to the end of the collumns 

pcadapt.pos.info <- as_tibble(paste(pcadapt.pos.info$value, " \\"))
 
#write_csv(pcadapt.pos.info, "C:/Users/Rebecca/Colostate/GhalamborLab - mysis/data/filtered_data/imputed_data/mysis.pcadapt.BLAST.fasta.coor.csv", quote=F, col_names=F)



```


We can then use the BLASTn tool to blast the fasta assembly.
Note that I couldn't get this installed on alpine, so I installed it on my ovis account. 


```{sh eval=FALSE, include=FALSE}

#To use the command line tool Blast+ from NCBI, follow the instructions outlined for the source tarbal option from the ncbi website 
https://www.ncbi.nlm.nih.gov/books/NBK279671/
#note the make option take ~ 1 hour to run on ovis


#update bash profile to the  c++/ReleaseMT/bin directory 

#now we can use the remote BLAST servers to query multiple fastas

# 
# now we extract the sequences with the following bash script, "pcadapt_snps_fasta.sh"

#note that catalog.fa is gziped after populations. need to decompress using gunzip and then change the filename to fasta
#fa is in fasta format. Samtools just won't read it unless it's the right filename

#!/bin/bash

samtools faidx \
catalog.fasta \
3213:0-350  \
3297:0-350  \
3421:0-350  \
3807:0-350  \
5172:0-350  \
5191:0-350  \
5377:0-350  \
5655:0-350  \
5866:0-350  \
6356:0-350  \
6685:0-350  \
7230:0-350  \
7527:0-350  \
7792:0-350  \
7865:0-350  \
8059:0-350  \
8128:0-350  \
8422:0-350  \
8608:0-350  \
8853:0-350  \
9303:0-350  \
10059:0-350  \
10208:0-350  \
10506:0-350  \
11701:0-350  \
12841:0-350  \
14273:0-350  \
14945:0-350  \
15424:0-350  \
16705:0-350  \
17710:0-350  \
18346:0-350  \
18742:0-350  \
18791:0-350  \
19341:0-350  \
22093:0-350  \
22137:0-350  \
22237:0-350  \
23036:0-350  \
23232:0-350  \
23277:0-350  \
23335:0-350  \
23634:0-350  \
26578:0-350  \
27559:0-350  \
28852:0-350  \
29616:0-350  \
30885:0-350  \
31257:0-350  \
32068:0-350  \
34115:0-350  \
34685:0-350  \
34836:0-350  \
35526:0-350  \
36727:0-350  \
36977:0-350  \
37418:0-350  \
37600:0-350  \
37679:0-350  \
37909:0-350  \
38400:0-350  \
38528:0-350  \
39641:0-350  \
40967:0-350  \
41013:0-350  \
41109:0-350  \
45019:0-350  \
45573:0-350  \
46522:0-350 > blast_pcadapt.fasta 

#note that it failed to fetch sequence in un:230297-280297


#we can then do the same thing with the RDA outliers 

# 
# extract the sequences from the reference genome folder with the following bash script, "RDA_snps_fasta.sh"

#!/bin/bash

samtools faidx \
catalog.fasta \
11229:0-350  \
11229:0-350  \
20540:0-350  \
25836:0-350  \
31585:0-350  \
31585:0-350  \
32048:0-350  \
32048:0-350  \
36807:0-350  \
46174:0-350  \
52499:0-350  \
53238:0-350  \
56281:0-350  \
56281:0-350  \
62904:0-350  \
62904:0-350  \
64330:0-350  \
64330:0-350  \
66038:0-350  \
66038:0-350  \
71299:0-350  \
71299:0-350  \
72788:0-350  \
73172:0-350  \
73172:0-350  \
90804:0-350  \
90804:0-350  \
92352:0-350  \
107167:0-350  \
107167:0-350  \
346935:0-350  \
346935:0-350  \
172:0-350  \
172:0-350  \
618:0-350  \
894:0-350  \
894:0-350  \
1175:0-350  \
3297:0-350  \
4802:0-350  \
7287:0-350  \
7344:0-350  \
7344:0-350  \
8059:0-350  \
8059:0-350  \
8775:0-350  \
8775:0-350  \
9308:0-350  \
9308:0-350  \
10832:0-350  \
11160:0-350  \
11160:0-350  \
11457:0-350  \
11457:0-350  \
12708:0-350  \
12708:0-350  \
17491:0-350  \
17491:0-350  \
18235:0-350  \
18235:0-350  \
19798:0-350  \
19798:0-350  \
20439:0-350  \
21804:0-350  \
21804:0-350  \
22889:0-350  \
22889:0-350  \
23083:0-350  \
23083:0-350  \
23833:0-350  \
25058:0-350  \
25774:0-350  \
26082:0-350  \
26082:0-350  \
26115:0-350  \
26853:0-350  \
26853:0-350  \
26911:0-350  \
26911:0-350  \
27452:0-350  \
27452:0-350  \
27646:0-350  \
29220:0-350  \
29220:0-350  \
31389:0-350  \
31389:0-350  \
31456:0-350  \
31515:0-350  \
31554:0-350  \
31554:0-350  \
32270:0-350  \
32320:0-350  \
32792:0-350  \
32792:0-350  \
33551:0-350  \
33551:0-350  \
34035:0-350  \
34035:0-350  \
35019:0-350  \
35019:0-350  \
35374:0-350  \
35374:0-350  \
35433:0-350  \
35433:0-350  \
35814:0-350  \
36550:0-350  \
36758:0-350  \
37703:0-350  \
37714:0-350  \
37714:0-350  \
39044:0-350  \
39044:0-350  \
39600:0-350  \
39670:0-350  \
39670:0-350  \
40250:0-350  \
40250:0-350  \
42879:0-350  \
42879:0-350  \
46926:0-350  \
46926:0-350  \
47441:0-350  \
47441:0-350  \
48009:0-350  \
49384:0-350  \
49384:0-350  \
50013:0-350  \
51488:0-350  \
52323:0-350  \
52323:0-350  \
54157:0-350  \
54762:0-350  \
54762:0-350  \
54780:0-350  \
54780:0-350  \
55309:0-350  \
55309:0-350  \
56330:0-350  \
56330:0-350  \
58285:0-350  \
58285:0-350  \
61795:0-350  \
61795:0-350  \
61931:0-350  \
61931:0-350  \
64533:0-350  \
64533:0-350  \
65453:0-350  \
65453:0-350  \
67305:0-350  \
67305:0-350  \
67335:0-350  \
67335:0-350  \
67407:0-350  \
67407:0-350  \
69359:0-350  \
69359:0-350  \
72824:0-350  \
72824:0-350  \
76565:0-350  \
76565:0-350  \
77961:0-350  \
77961:0-350  \
81566:0-350  \
81566:0-350  \
82224:0-350  \
85377:0-350  \
85377:0-350  \
87420:0-350  \
87420:0-350  \
87541:0-350  \
87541:0-350  \
88177:0-350  \
88177:0-350  \
101794:0-350  \
104766:0-350  \
107385:0-350  \
107385:0-350  \
112721:0-350  \
112721:0-350  \
123719:0-350  \
123719:0-350  \
151013:0-350  \
151013:0-350  \
210842:0-350  \
350637:0-350  \
387474:0-350  \
387474:0-350  \
557482:0-350  \
557482:0-350  \
593414:0-350  \
593414:0-350  \
715827:0-350  \
715827:0-350  \
726436:0-350  \
771790:0-350  \
771790:0-350  \
864120:0-350  \
864120:0-350  \
943222:0-350  \
943222:0-350  \
988329:0-350  \
992881:0-350  \
992881:0-350  \
1043671:0-350  \
1043671:0-350  \
1063000:0-350  \ > blast_fasta_RDA.fasta 


#note that you need to save the above scripts as text files and then read into correns and get rid of the DOS line breaks using 
##    tr -d '\r' < pcadapt_snps_fasta.txt > pcadapt_snps_fasta.sh

#can then just run the scripts locally. 

#then submit the list using the BLAST+ software. One of the command line options is “-remote”, which sends the search to NCBI BLAST servers, avoiding the need to install and maintain local databases.
#use “nr/nt” database and with setting parameters max target sequences to 100, expect thresholds to 10 (default), word size to 28 (default) and max matches in a query to 1. We considered a locus homologous if the e‐value returned was smaller than 1.0 e−10.


#Use script Blast_pcadapt.sh

#!/bin/bash
#SBATCH --job-name=mysis_Blast
#SBATCH --output=/home/rgcheek/mysis/mysis_Blast.out
#SBATCH --error=/home/rgcheek/mysis/mysis_Blast.err
#SBATCH --mail-user=Rebecca.G.Cheek@gmail.com
#SBATCH --mail-type=END
#SBATCH --ntasks=1

/home/rgcheek/bin/ncbi-blast-2.13.0+-src/c++/ReleaseMT/bin/blastn -query /home/rgcheek/mysis/blast_pcadapt.fasta -db nt -remote -max_target_seqs 100 -max_hsps 1 -outfmt "7 delim=, qseqid sacc evalue bitscore qcovus pident" -out /home/rgcheek/mysis/blast_pcadapt_annotation


#Then the same thing for the rda results 

#Use script 08.5-Blast_rda.sh

#!/bin/bash
#SBATCH --job-name=rda_Blast
#SBATCH --output=/home/rgcheek/mysis/mysis_Blast_RDA.out
#SBATCH --error=/home/rgcheek/mysis/blastmysis_Blast_RDA.err
#SBATCH --mail-user=Rebecca.G.Cheek@gmail.com
#SBATCH --mail-type=END
#SBATCH --ntasks=1

/home/rgcheek/bin/ncbi-blast-2.13.0+-src/c++/ReleaseMT/bin/blastn -query /home/rgcheek/mysis/blast_fasta_RDA.fasta -db nt -remote -max_target_seqs 100 -max_hsps 1 -outfmt "7 delim=, qseqid sacc evalue bitscore qcovus pident" -out /home/rgcheek/mysis/blast_RDA_annotation



```

Extract the annotation information for the outliers detected by PCAdapt and the RDA and assemble them all into a pretty table
```{r}

pca.ann <- read.delim("C:/Users/Rebecca/Colostate/GhalamborLab - mysis/data/filtered_data/imputed_data/blast_pcadapt_annotation", header = F,sep = ",", quote = "\"", comment.char = "#")


colnames(pca.ann) <- c("query_id", "subject_accession", "evalue", "bit_score", "percent_query_coverage_per_uniq_subject", "percent_identity")
 


#filter NAs from ensemble ID since those are the ones without any annotation

## define a helper function
empty_as_na <- function(x){
    if("factor" %in% class(x)) x <- as.character(x) ## since ifelse wont work with factors
    ifelse(as.character(x)!="", x, NA)
}

## transform all columns
pca.ann<- pca.ann %>% 
  mutate_each(funs(empty_as_na)) 



#Use the R packages mygene and biomaRt to get go terms and functional information for each acession number using their 
#Get the entrez id's from mygene to get the annotation and go terms to merge 

out <- as_tibble(mygene::queryMany(pca.ann$subject_accession, scopes=c("symbol", "reporter","accession"), fields=c("entrezgene","uniprot")))

pca.ann$entrezgene_id <- out$entrezgene

pca.ann <- na.omit(pca.ann, cols="entrezgene_id")


#get the gene names
gene_test <- as_tibble(mygene::getGenes(as.list(pca.ann$entrezgene_id)))

pca.ann$gene_name <- gene_test$name


#write a csv of the results and just look up the go terms cus bioRmart isnt working witout a specific database gd 

#write.csv(pca.ann,"C:/Users/Rebecca/Colostate/GhalamborLab - mysis/data/filtered_data/imputed_data/blast_pcadapt_annotation.csv", row.names = F )


#####
#Now the same thing for the RDA results
#####

RDA.ann <- read.delim("C:/Users/Rebecca/Colostate/GhalamborLab - Documents/Group Projects/mysis/data/filtered_data/imputed_data/adaptive_snps/blast_RDA_annotation", header = F, sep = ",", quote = "\"", comment.char = "#")

colnames(RDA.ann) <- c("query_id", "subject_accession", "evalue", "bit_score", "percent_query_coverage_per_uniq_subject", "percent_identity")


#Use the R packages mygene and biomaRt to get go terms and functional information for each acession number
#Get the entrez id's from mygene to get the annotation and go terms to merge 

out <- as_tibble(mygene::queryMany(RDA.ann$subject_accession, scopes=c("symbol", "reporter","accession"), fields=c("entrezgene","uniprot")))

RDA.ann$entrezgene_id <- out$entrezgene

#filter NAs from ensemble ID since those are the ones without any annotation
## transform all columns
RDA.ann<-RDA.ann %>% 
  mutate_each(funs(empty_as_na)) 

RDA.ann <- na.omit(RDA.ann, cols="entrezgene_id")


#get the gene names
gene_test <- as_tibble(mygene::getGenes(as.list(RDA.ann$entrezgene_id)))

RDA.ann$gene_name <- gene_test$name


#write a csv of the results and just look up the go terms 

#write.csv(RDA.ann,"C:/Users/Rebecca/Colostate/GhalamborLab - Documents/Group Projects/mysis/data/filtered_data/imputed_data/adaptive_snps/blast_RDA_annotation.csv", row.names = F )

```





